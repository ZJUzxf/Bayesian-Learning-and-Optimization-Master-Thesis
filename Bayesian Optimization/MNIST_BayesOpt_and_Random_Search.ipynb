{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST BayesOpt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hFjWJJA1QuR",
        "colab_type": "text"
      },
      "source": [
        "# Keras neural network for MNIST classification\n",
        "\n",
        "https://github.com/shibuiwilliam/keras_gpyopt/blob/master/bopt_nn.ipynb\n",
        "\n",
        "\n",
        "This experiment defined a 2-layer Dense neural network whose hyperparameters are tuned via Bayesian optimization after a warm start.\n",
        "\n",
        "That is, its performance is already quite good- BayesOpt here further fine-tunes the model while:\n",
        "- Monitoring loss and accuracy (on a left-out test set, batch-wise); later: will try to implement *aleatoric* and *epistemic* uncertainties too\n",
        "- For a choice of *activation function*, these two are calculated based on the network's dropout rates, hidden layer sizes, # epochs, batch size, and validation split\n",
        "- For each activation function, the result of each Bayesian optimization iteration is saved as a row in a dataframe, and this is then examined in a regression setting for statistical significance of hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9trSJISn1IMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install GPy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izOmXXy51YtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install GPyOpt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqoQErpSzT3U",
        "colab_type": "code",
        "outputId": "cb055be5-d12d-41c9-ffda-29058bfce08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "import GPy, GPyOpt\n",
        "import numpy as np\n",
        "import pandas as pds\n",
        "import random\n",
        "from keras.layers import Activation, Dropout, BatchNormalization, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import mnist\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 240 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCPGkUE_1cD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST class\n",
        "class MNIST():\n",
        "    def __init__(self, first_input=784, last_output=10,\n",
        "                 l1_out=512, \n",
        "                 l2_out=512, \n",
        "                 l1_drop=0.2, \n",
        "                 l2_drop=0.2, \n",
        "                 batch_size=100, \n",
        "                 epochs=10, \n",
        "                 validation_split=0.1):\n",
        "        self.__first_input = first_input\n",
        "        self.__last_output = last_output\n",
        "        self.l1_out = l1_out\n",
        "        self.l2_out = l2_out\n",
        "        self.l1_drop = l1_drop\n",
        "        self.l2_drop = l2_drop\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.validation_split = validation_split\n",
        "        self.__x_train, self.__x_test, self.__y_train, self.__y_test = self.mnist_data()\n",
        "        self.__model = self.mnist_model()\n",
        "        \n",
        "    # load mnist data from keras dataset\n",
        "    def mnist_data(self):\n",
        "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "        X_train = X_train.reshape(60000, 784)\n",
        "        X_test = X_test.reshape(10000, 784)\n",
        "\n",
        "        X_train = X_train.astype('float32')\n",
        "        X_test = X_test.astype('float32')\n",
        "        X_train /= 255\n",
        "        X_test /= 255\n",
        "\n",
        "        Y_train = np_utils.to_categorical(y_train, 10)\n",
        "        Y_test = np_utils.to_categorical(y_test, 10)\n",
        "        return X_train, X_test, Y_train, Y_test\n",
        "    \n",
        "    # mnist model\n",
        "    def mnist_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(self.l1_out, input_shape=(self.__first_input,)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(self.l1_drop))\n",
        "        model.add(Dense(self.l2_out))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(self.l2_drop))\n",
        "        model.add(Dense(self.__last_output))\n",
        "        model.add(Activation('softmax'))\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "    \n",
        "    # fit mnist model\n",
        "    def mnist_fit(self):\n",
        "        early_stopping = EarlyStopping(patience=0, verbose=1)\n",
        "        \n",
        "        self.__model.fit(self.__x_train, self.__y_train,\n",
        "                       batch_size=self.batch_size,\n",
        "                       epochs=self.epochs,\n",
        "                       verbose=0,\n",
        "                       validation_split=self.validation_split,\n",
        "                       callbacks=[early_stopping])\n",
        "    \n",
        "    # evaluate mnist model\n",
        "    def mnist_evaluate(self):\n",
        "        self.mnist_fit()\n",
        "        \n",
        "        evaluation = self.__model.evaluate(self.__x_test, self.__y_test, batch_size=self.batch_size, verbose=0)\n",
        "        return evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wdiRFTA1nxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to run mnist class\n",
        "def run_mnist(first_input=784, last_output=10,\n",
        "              l1_out=512, l2_out=512, \n",
        "              l1_drop=0.2, l2_drop=0.2, \n",
        "              batch_size=100, epochs=10, validation_split=0.1):\n",
        "    \n",
        "    _mnist = MNIST(first_input=first_input, last_output=last_output,\n",
        "                   l1_out=l1_out, l2_out=l2_out, \n",
        "                   l1_drop=l1_drop, l2_drop=l2_drop, \n",
        "                   batch_size=batch_size, epochs=epochs, \n",
        "                   validation_split=validation_split)\n",
        "    mnist_evaluation = _mnist.mnist_evaluate()\n",
        "    return mnist_evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYks0Z84zsfn",
        "colab_type": "text"
      },
      "source": [
        "# Bayesian optimization for the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu5IIM9eEpXV",
        "colab_type": "text"
      },
      "source": [
        "The hyperparameters of the 2-layer neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elu07rCk1t-g",
        "colab_type": "code",
        "outputId": "25874dff-340f-43a4-cfad-53be935bd3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# bounds for hyper-parameters in mnist model\n",
        "# the bounds dict should be in order of continuous type and then discrete type\n",
        "bounds = [{'name': 'l1_drop',          'type': 'continuous',  'domain': (0.0, 0.5)},\n",
        "          {'name': 'l2_drop',          'type': 'continuous',  'domain': (0.0, 0.5)},\n",
        "          {'name': 'l1_out',           'type': 'discrete',    'domain': (64, 128, 256, 512, 1024)},\n",
        "          {'name': 'l2_out',           'type': 'discrete',    'domain': (64, 128, 256, 512, 1024)},\n",
        "          {'name': 'batch_size',       'type': 'discrete',    'domain': (32, 64)},\n",
        "          {'name': 'epochs',           'type': 'discrete',    'domain': (5, 10, 20)}]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.71 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUvrT8JbHX3Z",
        "colab_type": "text"
      },
      "source": [
        "Define the function to be optimized; it relies on loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddL-t-Ln1wGE",
        "colab_type": "code",
        "outputId": "bb82c4e2-d31b-4248-def1-b83ecfcc282c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# function to optimize mnist model\n",
        "accuracy_list = []\n",
        "loss_list = []\n",
        "l1_dropout_list = []\n",
        "l2_dropout_list = []\n",
        "l1_out_list = []\n",
        "l2_out_list = []\n",
        "batch_size_list = []\n",
        "epochs_list = []\n",
        "\n",
        "\n",
        "def f(x):\n",
        "    print(x)\n",
        "    #modify this function to create a dataframe keeping track of hyperparams. and performance\n",
        "    evaluation = run_mnist(\n",
        "        l1_drop = float(x[:,0]), \n",
        "        l2_drop = float(x[:,1]), \n",
        "        l1_out = int(x[:,2]),\n",
        "        l2_out = int(x[:,3]), \n",
        "        batch_size = int(x[:,4]), \n",
        "        epochs = int(x[:,5])) \n",
        "        #validation_split = float(x[:,0]))\n",
        "    accuracy_list.append(evaluation[1])\n",
        "    loss_list.append(evaluation[0])\n",
        "    l1_dropout_list.append(float(x[:,0]))\n",
        "    l2_dropout_list.append(float(x[:,1]))\n",
        "    l1_out_list.append(int(x[:,2]))\n",
        "    l2_out_list.append(int(x[:,3]))\n",
        "    batch_size_list.append(int(x[:,4]))\n",
        "    epochs_list.append(int(x[:,5]))\n",
        "    print(\"LOSS:\\t{0} \\t ACCURACY:\\t{1}\".format(evaluation[0], evaluation[1]))\n",
        "    #print(evaluation)\n",
        "    return evaluation[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 11.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC8yfbx81xPu",
        "colab_type": "code",
        "outputId": "093063cc-dbed-4ebe-c8e4-8d4cd79dd84d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# optimizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#default acquisition function is expected improvement... EI. Other options: { ‘MPI', ‘LCB’} <- will experiment with these as well\n",
        "\n",
        "# Choice of acquisition function?\n",
        "#acquisition = 'EI' \n",
        "acquisition = 'MPI'\n",
        "#acquisition = 'LCB'\n",
        "kernel = GPy.kern.Matern52(input_dim=1, variance=1.0, lengthscale=2.5) #default kernel is Matern 5/2, shown to work well on most tasks [Snoek et al., 2012]\n",
        "\n",
        "# 5 outputs by default... it takes 5 starting points to begin with! \n",
        "opt_mnist = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds, kernel=kernel, acquisition_type = acquisition, acquisition_jitter = 0.01)\n",
        "\n",
        "# optimize mnist model\n",
        "maxiter = 30\n",
        "opt_mnist.run_optimization(max_iter=maxiter) # if max_iter = x, then there will be x+5 results. By default, it takes 5 samples."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.21310759   0.21746308 128.         128.          32.\n",
            "   20.        ]]\n",
            "Epoch 00007: early stopping\n",
            "LOSS:\t0.08014777007705706 \t ACCURACY:\t0.9779\n",
            "[[3.19652002e-01 3.53879220e-01 5.12000000e+02 2.56000000e+02\n",
            "  6.40000000e+01 1.00000000e+01]]\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.07589345325692556 \t ACCURACY:\t0.9778\n",
            "[[4.20974561e-01 5.51086560e-02 1.02400000e+03 1.28000000e+02\n",
            "  3.20000000e+01 1.00000000e+01]]\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.07176869309709873 \t ACCURACY:\t0.9784\n",
            "[[  0.37322592   0.24677989  64.         128.          32.\n",
            "    5.        ]]\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.11593333527562208 \t ACCURACY:\t0.9642\n",
            "[[3.67357246e-01 3.95679621e-01 1.02400000e+03 6.40000000e+01\n",
            "  3.20000000e+01 1.00000000e+01]]\n",
            "Epoch 00006: early stopping\n",
            "LOSS:\t0.08741464113570838 \t ACCURACY:\t0.9768\n",
            "The set cost function is ignored! LCB acquisition does not make sense with cost.\n",
            "[[5.11609524e-04 4.78040378e-01 1.28000000e+02 6.40000000e+01\n",
            "  6.40000000e+01 2.00000000e+01]]\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.08414257805761881 \t ACCURACY:\t0.9734\n",
            "[[2.90779437e-04 3.27246203e-01 5.12000000e+02 6.40000000e+01\n",
            "  6.40000000e+01 1.00000000e+01]]\n",
            "Epoch 00003: early stopping\n",
            "LOSS:\t0.09463897392940708 \t ACCURACY:\t0.973\n",
            "[[4.99939625e-01 6.02477921e-02 5.12000000e+02 1.28000000e+02\n",
            "  3.20000000e+01 2.00000000e+01]]\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.07582270555538126 \t ACCURACY:\t0.9769\n",
            "[[4.99658416e-01 1.74956179e-01 5.12000000e+02 1.28000000e+02\n",
            "  6.40000000e+01 5.00000000e+00]]\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.09245867045223713 \t ACCURACY:\t0.9717\n",
            "[[4.99279059e-01 2.14177090e-02 1.02400000e+03 2.56000000e+02\n",
            "  3.20000000e+01 1.00000000e+01]]\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.07777756952506025 \t ACCURACY:\t0.9779\n",
            "[[4.98938946e-01 4.63349877e-01 5.12000000e+02 5.12000000e+02\n",
            "  6.40000000e+01 5.00000000e+00]]\n",
            "LOSS:\t0.07128406269839034 \t ACCURACY:\t0.9768\n",
            "[[  0.42097456   0.32949808 128.         256.          32.\n",
            "   20.        ]]\n",
            "Epoch 00008: early stopping\n",
            "LOSS:\t0.07916852392007132 \t ACCURACY:\t0.9752\n",
            "[[ 0.41771552  0.29044747 64.         64.         64.          5.        ]]\n",
            "LOSS:\t0.13602026159912348 \t ACCURACY:\t0.958\n",
            "[[4.97637139e-01 5.13172972e-02 1.28000000e+02 2.56000000e+02\n",
            "  3.20000000e+01 2.00000000e+01]]\n",
            "Epoch 00007: early stopping\n",
            "LOSS:\t0.08274382284199819 \t ACCURACY:\t0.9756\n",
            "[[4.22623766e-01 1.17545596e-01 1.28000000e+02 1.28000000e+02\n",
            "  3.20000000e+01 2.00000000e+01]]\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.09393744913637637 \t ACCURACY:\t0.9709\n",
            "[[3.18233900e-01 4.01340885e-01 1.02400000e+03 6.40000000e+01\n",
            "  6.40000000e+01 2.00000000e+01]]\n",
            "Epoch 00006: early stopping\n",
            "LOSS:\t0.06673256254019506 \t ACCURACY:\t0.9807\n",
            "[[3.16969357e-01 4.25995616e-01 1.02400000e+03 1.02400000e+03\n",
            "  6.40000000e+01 5.00000000e+00]]\n",
            "Epoch 00003: early stopping\n",
            "LOSS:\t0.07279214612981305 \t ACCURACY:\t0.9778\n",
            "[[3.14792340e-01 3.08120638e-01 5.12000000e+02 5.12000000e+02\n",
            "  6.40000000e+01 1.00000000e+01]]\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.07386458414560183 \t ACCURACY:\t0.9779\n",
            "[[3.12565879e-01 4.76630289e-01 5.12000000e+02 5.12000000e+02\n",
            "  6.40000000e+01 5.00000000e+00]]\n",
            "LOSS:\t0.07017948889168911 \t ACCURACY:\t0.9791\n",
            "[[3.10550068e-01 4.09861249e-01 1.02400000e+03 2.56000000e+02\n",
            "  3.20000000e+01 2.00000000e+01]]\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.07394392627360576 \t ACCURACY:\t0.9793\n",
            "[[3.0778392e-01 1.2151118e-02 1.0240000e+03 1.0240000e+03 3.2000000e+01\n",
            "  1.0000000e+01]]\n",
            "Epoch 00003: early stopping\n",
            "LOSS:\t0.0851954580952879 \t ACCURACY:\t0.9743\n",
            "[[3.23025950e-01 2.52612759e-02 6.40000000e+01 1.02400000e+03\n",
            "  6.40000000e+01 2.00000000e+01]]\n",
            "Epoch 00010: early stopping\n",
            "LOSS:\t0.08324604781456292 \t ACCURACY:\t0.9753\n",
            "[[2.16548161e-01 1.18720637e-01 5.12000000e+02 6.40000000e+01\n",
            "  6.40000000e+01 1.00000000e+01]]\n",
            "Epoch 00003: early stopping\n",
            "LOSS:\t0.0861871269620955 \t ACCURACY:\t0.9727\n",
            "[[  0.31809457   0.13820207 128.          64.          64.\n",
            "   10.        ]]\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.0970341030113399 \t ACCURACY:\t0.9694\n",
            "[[4.99790016e-01 1.87558008e-01 1.02400000e+03 1.02400000e+03\n",
            "  6.40000000e+01 5.00000000e+00]]\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.0651851618188899 \t ACCURACY:\t0.9796\n",
            "[[4.99228659e-01 1.30219335e-01 1.02400000e+03 1.28000000e+02\n",
            "  6.40000000e+01 5.00000000e+00]]\n",
            "LOSS:\t0.07077415678915568 \t ACCURACY:\t0.978\n",
            "[[4.98795877e-01 1.36207567e-01 2.56000000e+02 2.56000000e+02\n",
            "  3.20000000e+01 5.00000000e+00]]\n",
            "LOSS:\t0.08124652503067628 \t ACCURACY:\t0.9758\n",
            "[[4.99674969e-01 6.10571502e-02 5.12000000e+02 6.40000000e+01\n",
            "  6.40000000e+01 5.00000000e+00]]\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.0774827895606868 \t ACCURACY:\t0.9758\n",
            "[[4.99366957e-01 3.85689648e-03 1.28000000e+02 1.02400000e+03\n",
            "  3.20000000e+01 5.00000000e+00]]\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.09625135430321097 \t ACCURACY:\t0.9701\n",
            "[[4.99694646e-01 8.40385346e-02 1.02400000e+03 1.02400000e+03\n",
            "  6.40000000e+01 5.00000000e+00]]\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.08456869189930148 \t ACCURACY:\t0.9745\n",
            "[[  0.49983601   0.15751789  64.         128.          32.\n",
            "    5.        ]]\n",
            "LOSS:\t0.12302469981089234 \t ACCURACY:\t0.963\n",
            "[[8.77846679e-04 1.56947017e-01 1.02400000e+03 2.56000000e+02\n",
            "  3.20000000e+01 1.00000000e+01]]\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.07938071998308151 \t ACCURACY:\t0.9787\n",
            "[[2.30072574e-04 1.79915653e-01 1.28000000e+02 1.02400000e+03\n",
            "  6.40000000e+01 5.00000000e+00]]\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.10777955302111804 \t ACCURACY:\t0.9704\n",
            "[[3.14302734e-01 1.53169404e-01 1.28000000e+02 1.02400000e+03\n",
            "  3.20000000e+01 1.00000000e+01]]\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.09372046039733105 \t ACCURACY:\t0.9711\n",
            "[[  0.3142607    0.28827601 256.          64.          64.\n",
            "   10.        ]]\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.08251575255487115 \t ACCURACY:\t0.9751\n",
            "time: 25min 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppPo_Q61aLjo",
        "colab_type": "text"
      },
      "source": [
        "Time taken for Bayesian optimization:\n",
        "\n",
        "Acquisition:\n",
        "\n",
        "EI\n",
        "\n",
        "MPI\n",
        "\n",
        "LCB - 25 min 38 sec "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCVSWVRiixPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check that enough iterations took place... length here should be maxiter + 5\n",
        "print(len(loss_list)) \n",
        "#best hyperparams\n",
        "print(opt_mnist.x_opt)\n",
        "\n",
        "#plot convergence\n",
        "opt_mnist.plot_convergence()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIbbNzeRlnyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#put all results into a dataframe to be exported to .csv format\n",
        "import pandas as pd\n",
        "\n",
        "if acquisition == 'EI':\n",
        "  bayesOpt_performance_EI = pd.DataFrame(\n",
        "      {'Dropout in layer 1': l1_dropout_list,\n",
        "      'Dropout in layer 2': l2_dropout_list,\n",
        "      'Layer 1 size': l1_out_list,\n",
        "      'Layer 2 size': l2_out_list,\n",
        "      'Batch size': batch_size_list,\n",
        "      'Epochs': epochs_list,\n",
        "      #'Validation split': validation_split_list,\n",
        "      'Loss': loss_list,\n",
        "      'Accuracy': accuracy_list\n",
        "      })\n",
        "elif acquisition == 'MPI':\n",
        "  bayesOpt_performance_MPI = pd.DataFrame(\n",
        "      {'Dropout in layer 1': l1_dropout_list,\n",
        "      'Dropout in layer 2': l2_dropout_list,\n",
        "      'Layer 1 size': l1_out_list,\n",
        "      'Layer 2 size': l2_out_list,\n",
        "      'Batch size': batch_size_list,\n",
        "      'Epochs': epochs_list,\n",
        "      #'Validation split': validation_split_list,\n",
        "      'Loss': loss_list,\n",
        "      'Accuracy': accuracy_list\n",
        "      })\n",
        "elif acquisition == 'LCB':\n",
        "  bayesOpt_performance_LCB = pd.DataFrame(\n",
        "      {'Dropout in layer 1': l1_dropout_list,\n",
        "      'Dropout in layer 2': l2_dropout_list,\n",
        "      'Layer 1 size': l1_out_list,\n",
        "      'Layer 2 size': l2_out_list,\n",
        "      'Batch size': batch_size_list,\n",
        "      'Epochs': epochs_list,\n",
        "      #'Validation split': validation_split_list,\n",
        "      'Loss': loss_list,\n",
        "      'Accuracy': accuracy_list\n",
        "      })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQG7TQnumpS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(bayesOpt_performance)\n",
        "if acquisition == 'EI':\n",
        "  bayesOpt_performance_EI.to_csv(r'BayesOpt_Hyperparameters_keras_MNIST_EI.csv', header=True)\n",
        "if acquisition == 'MPI':\n",
        "  bayesOpt_performance_MPI.to_csv(r'BayesOpt_Hyperparameters_keras_MNIST_MPI.csv', header=True)\n",
        "if acquisition == 'LCB':\n",
        "  bayesOpt_performance_LCB.to_csv(r'BayesOpt_Hyperparameters_keras_MNIST_LCB.csv', header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy4V6Oi42CYh",
        "colab_type": "code",
        "outputId": "f90258a0-9e54-4871-e044-8df5bcb3dad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "\n",
        "# print optimized mnist model\n",
        "print(\"\"\"\n",
        "Optimized Parameters:\n",
        "\\t{0}:\\t{1}\n",
        "\\t{2}:\\t{3}\n",
        "\\t{4}:\\t{5}\n",
        "\\t{6}:\\t{7}\n",
        "\\t{8}:\\t{9}\n",
        "\\t{10}:\\t{11}\n",
        "\"\"\".format(bounds[0][\"name\"],opt_mnist.x_opt[0],\n",
        "           bounds[1][\"name\"],opt_mnist.x_opt[1],\n",
        "           bounds[2][\"name\"],opt_mnist.x_opt[2],\n",
        "           bounds[3][\"name\"],opt_mnist.x_opt[3],\n",
        "           bounds[4][\"name\"],opt_mnist.x_opt[4],\n",
        "           bounds[5][\"name\"],opt_mnist.x_opt[5]))\n",
        "           #bounds[6][\"name\"],opt_mnist.x_opt[6]))\n",
        "print(\"optimized loss: {0}\".format(opt_mnist.fx_opt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Optimized Parameters:\n",
            "\tl1_drop:\t0.2791510127474299\n",
            "\tl2_drop:\t0.41382603699229603\n",
            "\tl1_out:\t256.0\n",
            "\tl2_out:\t128.0\n",
            "\tbatch_size:\t32.0\n",
            "\tepochs:\t10.0\n",
            "\n",
            "optimized loss: 0.07014503737912454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3hT379N2GxC",
        "colab_type": "text"
      },
      "source": [
        "Retrieve best hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z57YheP2Gbh",
        "colab_type": "code",
        "outputId": "1ebe3385-5257-4951-8aea-f414d3c66335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "opt_mnist.x_opt\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.16108600e-01, 1.97594437e-01, 1.02400000e+03, 6.40000000e+01,\n",
              "       6.40000000e+01, 2.00000000e+01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FhYFMGpcT2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_mnist.plot_acquisition()\n",
        "opt_mnist.plot_convergence()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUUpRzNDZd6k",
        "colab_type": "text"
      },
      "source": [
        "# Random search\n",
        "\n",
        "Now we can see the performance of the random search model;\n",
        "its performance should look like white noise.\n",
        "\n",
        "This is coded from scratch, which is trivial. Using a Keras wrapper with the scikit learn RandomizedSearch was annoying.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzEmFlNn6kqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTTyvi86x8cV",
        "colab_type": "code",
        "outputId": "aca0c448-53cf-4e80-d54f-df9f2493b302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "maxiter = 35\n",
        "\n",
        "#hyperparameters:\n",
        "l1_drop_values = [] \n",
        "l2_drop_values = []\n",
        "l1_out_values = []\n",
        "l2_out_values = []\n",
        "batch_size_values = []\n",
        "epochs_values = []\n",
        "accuracy_list = []\n",
        "loss_list = []\n",
        "\n",
        "\n",
        "\n",
        "for i in range(maxiter):\n",
        "  l1_drop = random.uniform(0, 0.3)\n",
        "  l2_drop = random.uniform(0, 0.3)\n",
        "  l1_out = random.choice([64, 128, 256, 512, 1024])\n",
        "  l2_out = random.choice([64, 128, 256, 512, 1024])\n",
        "  batch_size = random.choice([32, 64])\n",
        "  epochs = random.choice([5, 10, 20])\n",
        "\n",
        "  l1_drop_values.append(l1_drop)\n",
        "  l2_drop_values.append(l2_drop)\n",
        "  l1_out_values.append(l1_out)\n",
        "  l2_out_values.append(l2_out)\n",
        "  batch_size_values.append(batch_size)\n",
        "  epochs_values.append(epochs)\n",
        "\n",
        "  evaluation = run_mnist(\n",
        "        l1_drop = l1_drop, \n",
        "        l2_drop = l2_drop, \n",
        "        l1_out = l1_out,\n",
        "        l2_out = l2_out, \n",
        "        batch_size = batch_size, \n",
        "        epochs = epochs) \n",
        "  accuracy_list.append(evaluation[1])\n",
        "  loss_list.append(evaluation[0])\n",
        "  print(\"LOSS:\\t{0} \\t ACCURACY:\\t{1}\".format(evaluation[0], evaluation[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.08393999278205447 \t ACCURACY:\t0.9763\n",
            "Epoch 00002: early stopping\n",
            "LOSS:\t0.12972128381417133 \t ACCURACY:\t0.9561\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.08095801948263252 \t ACCURACY:\t0.9767\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.0861539315050235 \t ACCURACY:\t0.9766\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.07943686439549784 \t ACCURACY:\t0.9772\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.0665393693373073 \t ACCURACY:\t0.9798\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.09553429095949978 \t ACCURACY:\t0.9713\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.069875609615969 \t ACCURACY:\t0.9784\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.07917471268810332 \t ACCURACY:\t0.9766\n",
            "Epoch 00003: early stopping\n",
            "LOSS:\t0.08126694226264954 \t ACCURACY:\t0.9759\n",
            "LOSS:\t0.08353986749184551 \t ACCURACY:\t0.9738\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.1141093005700037 \t ACCURACY:\t0.9688\n",
            "Epoch 00006: early stopping\n",
            "LOSS:\t0.10217970528267324 \t ACCURACY:\t0.9695\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.07490481636805925 \t ACCURACY:\t0.9779\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.07827365949400701 \t ACCURACY:\t0.9757\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.08102991795991547 \t ACCURACY:\t0.9764\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.08085255226679146 \t ACCURACY:\t0.9749\n",
            "Epoch 00003: early stopping\n",
            "LOSS:\t0.09368980635306798 \t ACCURACY:\t0.9724\n",
            "Epoch 00006: early stopping\n",
            "LOSS:\t0.08711312222850974 \t ACCURACY:\t0.974\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.0715570103177568 \t ACCURACY:\t0.9781\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.07113011239413172 \t ACCURACY:\t0.9788\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.08273971661757677 \t ACCURACY:\t0.9741\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.10118847359661012 \t ACCURACY:\t0.9682\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.07091352006387897 \t ACCURACY:\t0.9787\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.08250810963058611 \t ACCURACY:\t0.9751\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.09136816694274312 \t ACCURACY:\t0.976\n",
            "Epoch 00007: early stopping\n",
            "LOSS:\t0.08323324729264714 \t ACCURACY:\t0.9754\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.06701371525786817 \t ACCURACY:\t0.9798\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.07407456949194893 \t ACCURACY:\t0.9771\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.08033292549216421 \t ACCURACY:\t0.9758\n",
            "Epoch 00003: early stopping\n",
            "LOSS:\t0.0745337082629092 \t ACCURACY:\t0.9761\n",
            "Epoch 00005: early stopping\n",
            "LOSS:\t0.08046472480420488 \t ACCURACY:\t0.975\n",
            "Epoch 00004: early stopping\n",
            "LOSS:\t0.08330673395264894 \t ACCURACY:\t0.9734\n",
            "Epoch 00003: early stopping\n",
            "LOSS:\t0.07775974507816136 \t ACCURACY:\t0.9758\n",
            "Epoch 00009: early stopping\n",
            "LOSS:\t0.08628872956461273 \t ACCURACY:\t0.9749\n",
            "time: 18min 46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N-5yXAo2hNw",
        "colab_type": "code",
        "outputId": "448fce9e-e54f-40a0-86c0-c9e51233579b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#save result to pandas dataframe, then csv\n",
        "print(len(loss_list))\n",
        "import pandas as pd\n",
        "rs_performance_keras_mnist = pd.DataFrame({'Dropout in layer 1': l1_drop_values,\n",
        "      'Dropout in layer 2': l2_drop_values,\n",
        "      'Layer 1 size': l1_out_values,\n",
        "      'Layer 2 size': l2_out_values,\n",
        "      'Batch size': batch_size_values,\n",
        "      'Epochs': epochs_values,\n",
        "      'Loss': loss_list,\n",
        "      'Accuracy': accuracy_list\n",
        "      })\n",
        "\n",
        "rs_performance_keras_mnist.to_csv(r'Random_Search_Hyperparameters_keras_MNIST.csv', header=True)\n",
        "\n",
        "#Random search here took 18 min 46 seconds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35\n",
            "time: 15.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}