{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alexnet vs bayesian alexnet.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQtj6csAJ1PS",
        "colab_type": "text"
      },
      "source": [
        "# *A Bayesian CNN with uncertainty measures*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-zCoSobQc-b",
        "colab_type": "text"
      },
      "source": [
        "**Source**:\n",
        "*https://github.com/kumar-shridhar/PyTorch-Softplus-Normalization-Uncertainty-Estimation-Bayesian-CNN/blob/master/main.ipynb*\n",
        "\n",
        "**Paper**:\n",
        "*https://arxiv.org/abs/1806.05978*\n",
        "\n",
        "\n",
        "*Aleatoric* = uncertainty due to inherent noisiness of **data**\n",
        "\n",
        "*Epistemic* = uncertainty due to the **model**.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mqzFKfpJkg9",
        "colab_type": "code",
        "outputId": "58ce8cf5-ef0f-4413-dc43-8f51fe417a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/kumar-shridhar/PyTorch-Softplus-Normalization-Uncertainty-Estimation-Bayesian-CNN.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch-Softplus-Normalization-Uncertainty-Estimation-Bayesian-CNN'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSIgMYZoJqH-",
        "colab_type": "code",
        "outputId": "ca5e2a43-4bad-448b-a345-10223599614b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!git clone https://github.com/kumar-shridhar/PyTorch-BayesianCNN.git \n",
        "!ls "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch-BayesianCNN'...\n",
            "remote: Enumerating objects: 223, done.\u001b[K\n",
            "remote: Counting objects: 100% (223/223), done.\u001b[K\n",
            "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
            "remote: Total 1214 (delta 118), reused 186 (delta 84), pack-reused 991\u001b[K\n",
            "Receiving objects: 100% (1214/1214), 67.72 MiB | 32.09 MiB/s, done.\n",
            "Resolving deltas: 100% (719/719), done.\n",
            "PyTorch-BayesianCNN\t\t\t\t\t\t    sample_data\n",
            "PyTorch-Softplus-Normalization-Uncertainty-Estimation-Bayesian-CNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPnova3nMh9V",
        "colab_type": "code",
        "outputId": "06f52477-0613-4f3a-9995-4482df5bca15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#change working directory to access inner modules\n",
        "%cd PyTorch-BayesianCNN\n",
        "%cd Image Recognition\n",
        "#check working directory\n",
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PyTorch-BayesianCNN\n",
            "[Errno 2] No such file or directory: 'Image Recognition'\n",
            "/content/PyTorch-BayesianCNN\n",
            "/content/PyTorch-BayesianCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6RBDkMrMjet",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2666d040-b2b2-4238-e150-9d5412a97e65"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import argparse\n",
        "import datetime\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "from collections import OrderedDict\n",
        "from torchvision import datasets"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 7.91 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3AhRSbsMmsm",
        "colab_type": "code",
        "outputId": "9556f843-3b90-4242-9dd1-0d9c7f567378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net_type = 'alexnet'\n",
        "#dataset = 'CIFAR10'\n",
        "dataset = 'MNIST'\n",
        "outputs = 10\n",
        "inputs = 3\n",
        "resume = False\n",
        "n_epochs = 20\n",
        "lr = 0.01\n",
        "weight_decay = 0.0005\n",
        "num_samples = 1\n",
        "beta_type = \"Blundell\"\n",
        "resize=32"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.19 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO_yN7pLMpmT",
        "colab_type": "code",
        "outputId": "b18a5d1b-95ef-4575-9ba7-e57eca23d512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Hyper Parameter settings\n",
        "use_cuda = torch.cuda.is_available()\n",
        "torch.cuda.set_device(0)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.28 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyeXAr6VMshs",
        "colab_type": "code",
        "outputId": "bd8ba6e2-0598-4ef8-ccaf-9a33322cc3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load... maybe this should be smaller (32)\n",
        "batch_size = 32\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.08 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ow4zCENMtT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert data to a normalized torch.FloatTensor\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "# choose the training and test datasets\n",
        "if dataset == 'CIFAR10':\n",
        "  train_data = datasets.CIFAR10('data', train=True,\n",
        "                              download=True, transform=transform_cifar)\n",
        "  test_data = datasets.CIFAR10('data', train=False,\n",
        "                             download=True, transform=transform_cifar)\n",
        "  train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                           num_workers=num_workers)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "                                          num_workers=num_workers)\n",
        "  \n",
        "elif dataset == 'MNIST':\n",
        "  train_data = datasets.MNIST('data', train=True,\n",
        "                              download=True, transform=transforms.Compose([transforms.ToTensor(),]))\n",
        "  test_data = datasets.MNIST('data', train=False,\n",
        "                              download=True, transform=transforms.Compose([transforms.ToTensor(),]))\n",
        "  train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                           num_workers=num_workers)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "                                          num_workers=num_workers)\n",
        "  \n",
        "  # train_loader = torch.utils.data.DataLoader(\n",
        "  #       datasets.MNIST('mnist-data/', train=True, download=True,\n",
        "  #                      transform=transforms.Compose([transforms.ToTensor(),])),\n",
        "  #                      batch_size=batch_size, shuffle=True)#, worker_init_fn=np.random.seed(12))\n",
        "\n",
        "  # test_loader = torch.utils.data.DataLoader(\n",
        "  #       datasets.MNIST('mnist-data/', train=False, transform=transforms.Compose([transforms.ToTensor(),])),\n",
        "  #                      batch_size=batch_size, shuffle=True)#, worker_init_fn=np.random.seed(12))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgGB0dl_M2c5",
        "colab_type": "code",
        "outputId": "61768401-0cbf-45a2-b737-1de72d3524ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# specify the image classes\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "#classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.39 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh5rvaQrNOE4",
        "colab_type": "code",
        "outputId": "12035316-adc2-4611-eca2-ce44417f69c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class BBBConv2d(nn.Module):\n",
        "    def __init__(self, q_logvar_init, p_logvar_init, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n",
        "        super(BBBConv2d, self).__init__()\n",
        "        if in_channels % groups != 0:\n",
        "            raise ValueError('in_channels must be divisible by groups')\n",
        "        if out_channels % groups != 0:\n",
        "            raise ValueError('out_channels must be divisible by groups')\n",
        "        self.q_logvar_init = q_logvar_init\n",
        "        self.p_logvar_init = p_logvar_init\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.groups = groups\n",
        "        self.bias = bias\n",
        "\n",
        "        self.mu_weight = nn.Parameter(torch.Tensor(out_channels, in_channels // groups, kernel_size, kernel_size))\n",
        "        self.sigma_weight = nn.Parameter(torch.Tensor(out_channels, in_channels // groups, kernel_size, kernel_size))\n",
        "        self.register_buffer('eps_weight', torch.Tensor(out_channels, in_channels // groups, kernel_size, kernel_size))\n",
        "        \n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        n = self.in_channels\n",
        "        n *= self.kernel_size ** 2\n",
        "        stdv = 1.0 / math.sqrt(n)\n",
        "        self.mu_weight.data.uniform_(-stdv, stdv)\n",
        "        self.sigma_weight.data.fill_(self.p_logvar_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "    def convprobforward(self, input):\n",
        "        sig_weight = torch.exp(self.sigma_weight)\n",
        "        weight = self.mu_weight + sig_weight * self.eps_weight.normal_()\n",
        "        kl_ = math.log(self.q_logvar_init) - self.sigma_weight + (sig_weight**2 + self.mu_weight**2) / (2 * self.q_logvar_init ** 2) - 0.5\n",
        "        bias = None\n",
        "        \n",
        "        out = F.conv2d(input, weight, bias, self.stride, self.padding, self.dilation, self.groups)\n",
        "        kl = kl_.sum() \n",
        "        return out, kl"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 25.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQm7_zGzNPlw",
        "colab_type": "code",
        "outputId": "7accf617-4f1e-4831-c985-0f4513c8a4d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "class BBBLinearFactorial(nn.Module):\n",
        "    def __init__(self, q_logvar_init, p_logvar_init, in_features, out_features, bias=False):\n",
        "        super(BBBLinearFactorial, self).__init__()\n",
        "        self.q_logvar_init = q_logvar_init\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.p_logvar_init = p_logvar_init\n",
        "        self.mu_weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.sigma_weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.register_buffer('eps_weight', torch.Tensor(out_features, in_features))\n",
        "        \n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.mu_weight.size(1))\n",
        "        self.mu_weight.data.uniform_(-stdv, stdv)\n",
        "        self.sigma_weight.data.fill_(self.p_logvar_init)\n",
        "        self.eps_weight.data.zero_()\n",
        "\n",
        "    def forward(self, input):\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "\n",
        "    def fcprobforward(self, input):\n",
        "        sig_weight = torch.exp(self.sigma_weight)\n",
        "        weight = self.mu_weight + sig_weight * self.eps_weight.normal_()\n",
        "        kl_ = math.log(self.q_logvar_init) - self.sigma_weight + (sig_weight**2 + self.mu_weight**2) / (2 * self.q_logvar_init ** 2) - 0.5\n",
        "        bias = None\n",
        "        out = F.linear(input, weight, bias)\n",
        "        kl = kl_.sum() \n",
        "        return out, kl"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 29.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvqZ7b5aNR8a",
        "colab_type": "code",
        "outputId": "c5e74f5e-4b7a-489e-dd70-1fce78617972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class BBBAlexNet(nn.Module):\n",
        "    '''The architecture of AlexNet with Bayesian Layers'''\n",
        "\n",
        "    def __init__(self, outputs, inputs):\n",
        "        super(BBBAlexNet, self).__init__()\n",
        "\n",
        "        self.q_logvar_init = 0.05\n",
        "        self.p_logvar_init = math.log(0.05)\n",
        " \n",
        "        self.classifier = BBBLinearFactorial(self.q_logvar_init, self.p_logvar_init, 1* 1 * 128, outputs)\n",
        "\n",
        "        self.conv1 = BBBConv2d(self.q_logvar_init, self.p_logvar_init, inputs, 64, kernel_size=11, stride=4, padding=5)\n",
        "        self.soft1 = nn.Softplus()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = BBBConv2d(self.q_logvar_init,  self.p_logvar_init, 64, 192, kernel_size=5, padding=2)\n",
        "        self.soft2 = nn.Softplus()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = BBBConv2d(self.q_logvar_init, self.p_logvar_init, 192, 384, kernel_size=3, padding=1)\n",
        "        self.soft3 = nn.Softplus()\n",
        "\n",
        "        self.conv4 = BBBConv2d(self.q_logvar_init, self.p_logvar_init, 384, 256, kernel_size=3, padding=1)\n",
        "        self.soft4 = nn.Softplus()\n",
        "\n",
        "        self.conv5 = BBBConv2d(self.q_logvar_init, self.p_logvar_init, 256, 128, kernel_size=3, padding=1)\n",
        "        self.soft5 = nn.Softplus()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # self.flatten = FlattenLayer(1 * 1 * 128)\n",
        "        # self.fc1 = BBBLinearFactorial(q_logvar_init, N, p_logvar_init, 1* 1 * 128, outputs)\n",
        "\n",
        "\n",
        "        layers = [self.conv1, self.soft1, self.pool1, self.conv2, self.soft2, self.pool2, self.conv3, self.soft3,\n",
        "                  self.conv4, self.soft4, self.conv5, self.soft5, self.pool3]\n",
        "\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def probforward(self, x):\n",
        "        kl = 0\n",
        "        for layer in self.layers:\n",
        "            if hasattr(layer, 'convprobforward') and callable(layer.convprobforward):\n",
        "                x, _kl, = layer.convprobforward(x)\n",
        "            else:\n",
        "                x = layer.forward(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x, _kl = self.classifier.fcprobforward(x)\n",
        "        kl += _kl\n",
        "        logits = x\n",
        "        return logits, kl"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 37.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlroMs6rNoVQ",
        "colab_type": "code",
        "outputId": "8b761132-2250-45de-a4de-150aefef01ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Architecture\n",
        "net_type = 'alexnet'\n",
        "if (net_type == 'lenet'):\n",
        "    net = BBBLeNet(outputs,inputs)\n",
        "elif (net_type == 'alexnet'):\n",
        "    net = BBBAlexNet(outputs, inputs)\n",
        "elif (net_type == '3conv3fc'):\n",
        "    net = BBB3Conv3FC(outputs,inputs)\n",
        "else:\n",
        "    print('Error : Network should be either [LeNet / AlexNet / 3Conv3FC]')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 26.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ayvbHh7NVb-",
        "colab_type": "code",
        "outputId": "cdbf6aa0-aa38-4579-a2ea-000ec7be4f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#check if cuda is available\n",
        "if use_cuda:\n",
        "    net.cuda()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 15.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqV32xDuPcTL",
        "colab_type": "code",
        "outputId": "3e74a855-24b3-4a84-cac6-23437d4d3377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create checkpoint path to save\n",
        "ckpt_name = f'model_{net_type}_{dataset}_bayesian.pt'\n",
        "ckpt_name"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_alexnet_MNIST_bayesian.pt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.04 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFnNF2MGPhWy",
        "colab_type": "code",
        "outputId": "462e175e-d752-40f2-a06d-b548bec45fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_beta(batch_idx, m, beta_type):\n",
        "    if beta_type == \"Blundell\":\n",
        "        beta = 2 ** (m - (batch_idx + 1)) / (2 ** m - 1)\n",
        "    elif beta_type == \"Soenderby\":\n",
        "        beta = min(epoch / (num_epochs // 4), 1)\n",
        "    elif beta_type == \"Standard\":\n",
        "        beta = 1 / m\n",
        "    else:\n",
        "        beta = 0\n",
        "    return beta"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 6.82 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdxPPcutPjQl",
        "colab_type": "code",
        "outputId": "83cdc437-03f3-4ff5-ff41-11f1d9b8647b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def elbo(out, y, kl, beta):\n",
        "    loss = F.cross_entropy(out, y)\n",
        "    return loss + beta * kl"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.32 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMjq4ijWPkyw",
        "colab_type": "code",
        "outputId": "c7443ae6-8294-468b-b36e-bb3941f9eef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def get_beta(epoch_idx, N):\n",
        "    return 1.0 / N / 100"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.47 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G3Mee--Pn4s",
        "colab_type": "text"
      },
      "source": [
        "**Uncertainty estimation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_rvX5otPnDh",
        "colab_type": "code",
        "outputId": "f388a375-2694-4ef4-dd2d-d17edf4bdf80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def calc_uncertainty_softmax(output):\n",
        "    prediction = F.softmax(output, dim = 1)\n",
        "    results = torch.max(prediction, 1 )\n",
        "    p_hat = np.array(results[0].cpu().detach())\n",
        "    epistemic = np.mean(p_hat ** 2, axis=0) - np.mean(p_hat, axis=0) ** 2\n",
        "    #epistemic += epistemic \n",
        "    #print (epistemic)\n",
        "    aleatoric = np.mean(p_hat * (1-p_hat), axis = 0)\n",
        "    #aleatoric += aleatoric\n",
        "    #print (aleatoric)\n",
        "    return epistemic, aleatoric"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 8.19 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwYUXt2IPuKM",
        "colab_type": "text"
      },
      "source": [
        "But we will report **normalized** uncertainty measures:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gtrq03iPzd3",
        "colab_type": "code",
        "outputId": "1603f564-92c8-40d6-fd57-d8b80dd1b421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def normalization_function(x):\n",
        "    return (x) / torch.sum(x, dim=0)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.54 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjjbAfwkPtIW",
        "colab_type": "code",
        "outputId": "ab0b8bd4-8d3b-44a2-c95d-63e202b72d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def calc_uncertainty_normalized(output):\n",
        "    outputs = []\n",
        "    for t in range(1):\n",
        "        prediction = F.softplus(output.cpu())\n",
        "        prediction = normalization_function(prediction)\n",
        "        outputs.append(prediction)\n",
        "        \n",
        "    res = np.mean(prediction.numpy(), axis=0)\n",
        "    p_hat= torch.cat(outputs, 1)\n",
        "    p_hat=p_hat.numpy()\n",
        "    T=1\n",
        "    \n",
        "    aleatoric = np.diag(res) - p_hat.T.dot(p_hat)/p_hat.shape[0]\n",
        "#     aleatoric += aleatoric\n",
        "    tmp = p_hat - res  \n",
        "    epistemic = tmp.T.dot(tmp)/tmp.shape[0]\n",
        "#     epistemic += epistemic \n",
        "\n",
        "    #print(np.sum(epistemic, keepdims = True))\n",
        "    #print(np.sum(aleatoric, keepdims = True))\n",
        "    #p_hat = np.array(res)\n",
        "    #print (p_hat)\n",
        "    #epistemic = np.mean((p_hat) ** 2, axis=0) - np.mean((p_hat), axis=0) ** 2\n",
        "    #epistemic = np.mean((1-p_hat) ** 2, axis=0) - np.mean((1-p_hat), axis=0) ** 2\n",
        "    #epistemic += epistemic \n",
        "    #print (epistemic)\n",
        "    #aleatoric = np.mean((p_hat) * (1-(p_hat)), axis = 0)\n",
        "    #aleatoric = np.mean((1-p_hat), axis = 0) ** 2\n",
        "    #aleatoric += aleatoric\n",
        "    #print (aleatoric)\n",
        "    #print((np.sum(epistemic, keepdims = True)), (np.sum(aleatoric, keepdims = True)))\n",
        "    return (np.sum(epistemic, keepdims = True)), (np.sum(aleatoric, keepdims = True))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 15.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6HrY1zaP6NA",
        "colab_type": "text"
      },
      "source": [
        "# Bayesian training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVvEcvbZQJDL",
        "colab_type": "code",
        "outputId": "b99ce74d-9366-4fe9-b2f5-5758b52ed5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def train(epoch):\n",
        "    print('Epoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs, kl = net.probforward(inputs)\n",
        "        loss = elbo(outputs, targets, kl, get_beta(epoch, len(train_data)))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = torch.max(outputs, dim=1)[1]\n",
        "        correct += torch.sum(pred.eq(targets)).item()\n",
        "        total += targets.numel()\n",
        "    print(f'[TRAIN] Acc: {100.*correct/total:.3f}')\n",
        "    #with open( writefile_train, 'a' ) as f:\n",
        "    #        writer = csv.writer(f)\n",
        "    #        writer.writerow([epoch, 100.*correct/total])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 13.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTZyTzXYQK6g",
        "colab_type": "code",
        "outputId": "e0169dcf-e2b5-4ad9-d47f-7d86cf80e60a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def test(epoch):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    accuracy_max = 0    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs, _ = net.probforward(inputs)\n",
        "            epistemic , aleatoric = calc_uncertainty_softmax(outputs)\n",
        "            norm_epistemic , norm_aleatoric = calc_uncertainty_normalized(outputs)\n",
        "            #print(epistemic)\n",
        "            #print(norm_epistemic[0][0])\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            accuracy = 100.*correct/total\n",
        "        print(f'[TEST] Acc: {accuracy:.3f}')\n",
        "        print(f'Epistemic Uncertainty: {epistemic:.6f}')\n",
        "        print(f'Aleatoric Uncertainty: {aleatoric:.6f}\\n')\n",
        "        #unlike authors originally do, report both raw and normalized uncertainties\n",
        "        print(f'Normalized Epistemic Uncertainty: {norm_epistemic[0][0]:.6f}')\n",
        "        print(f'Normalized Aleatoric Uncertainty: {norm_aleatoric[0][0]:.6f}\\n')\n",
        "        #print(map('Normalized Epistemic Uncertainty:{.6f}'.format,norm_epistemic[0]))\n",
        "        #with open( writefile_test, 'a' ) as f:\n",
        "        #    writer = csv.writer(f)\n",
        "        #    writer.writerow([epoch, 100.*correct/total, epistemic, aleatoric])\n",
        "        \n",
        "\n",
        "    torch.save(net.state_dict(), ckpt_name)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 16.7 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiiL-GElQNGp",
        "colab_type": "text"
      },
      "source": [
        "This has to be changed, we are not using the same number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ8C4DYzQLbB",
        "colab_type": "code",
        "outputId": "0b3893b4-f22f-40f7-80fb-b117cb786e53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# train for how many epochs?\n",
        "epochs = 20\n",
        "count = 0"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.35 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odk3kq8yQTRk",
        "colab_type": "text"
      },
      "source": [
        "**Bayesian training and reporting accuracy + uncertainties:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xvna5hOC4hf",
        "colab_type": "code",
        "outputId": "53fa3e94-eab2-4c52-cd7e-aebb3bdb5d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 2.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eLFO2anQR3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "e4058df5-55b5-41ae-d4b3-f66d1d51491a"
      },
      "source": [
        "from torch.optim import Adam\n",
        "import random\n",
        "\n",
        "\n",
        "torch.manual_seed(12)\n",
        "torch.cuda.manual_seed(12)\n",
        "np.random.seed(12)\n",
        "random.seed(12)\n",
        "\n",
        "torch.backends.cudnn.deterministic=True\n",
        "\n",
        "\n",
        "optimizer = Adam(net.parameters(), lr=lr)\n",
        "for _ in range(epochs):\n",
        "    train(count)\n",
        "    test(count)\n",
        "    count += 1\n",
        "lr /= 10"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-b7812acc973e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-38d0a5e9c625>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-91-63ce75f72ec1>\u001b[0m in \u001b[0;36mprobforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'convprobforward'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvprobforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_kl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvprobforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-26bec4b3e2c8>\u001b[0m in \u001b[0;36mconvprobforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkl_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 64 3 11 11, expected input[32, 1, 28, 28] to have 3 channels, but got 1 channels instead"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "time: 42.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkb8Ja7JnEze",
        "colab_type": "text"
      },
      "source": [
        "# Frequentist AlexNet on MNIST\n",
        "\n",
        "CIFAR10 later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbwNF6T_j9Pk",
        "colab_type": "code",
        "outputId": "ef802e14-0498-449d-fc4c-b99cbaa6e3b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def conv_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        #nn.init.xavier_uniform(m.weight, gain=np.sqrt(2))\n",
        "        nn.init.normal_(m.weight, mean=0, std=1)\n",
        "        nn.init.constant(m.bias, 0)\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, inputs=3):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(inputs, 64, kernel_size=11, stride=4, padding=5),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 18.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4XWpqpqCiTM",
        "colab_type": "code",
        "outputId": "90f74e5a-7eaa-4985-9131-c0d65a702aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def conv_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        #nn.init.xavier_uniform(m.weight, gain=np.sqrt(2))\n",
        "        nn.init.normal_(m.weight, mean=0, std=1)\n",
        "        nn.init.constant(m.bias, 0)\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes, inputs=3):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inputs, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        return(out)\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 18.7 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gRAtsW6nEh6",
        "colab_type": "code",
        "outputId": "fcb89302-2ced-45da-ddd8-ec25f3850ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = 'MNIST'\n",
        "outputs = 10\n",
        "inputs = 3\n",
        "n_epochs = 100\n",
        "lr = 0.001\n",
        "resize=32"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.74 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxqqTl3QnZrc",
        "colab_type": "code",
        "outputId": "b20fe7f4-df89-49e0-efc1-dca615f3fff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 32 \n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.03 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijiXymz0naDg",
        "colab_type": "code",
        "outputId": "8d63a38e-4c15-41fc-8317-d7440e6f9bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 9.79 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wVFIDCFo9ua",
        "colab_type": "code",
        "outputId": "03191959-a825-4840-8f6b-e1aafe4fc550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.29 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGoyHqRPo93Y",
        "colab_type": "code",
        "outputId": "d55d61de-9d6e-4c9d-f903-403428813c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "    sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "    num_workers=num_workers)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.09 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9M9FaRTo99u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac7aa980-0e13-46e4-c7b3-1ae80abcbee1"
      },
      "source": [
        "# specify the image classes\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.19 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "925czDPApNMG",
        "colab_type": "code",
        "outputId": "2a6e714c-3f9f-4ede-9264-ef877eac5e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Architecture\n",
        "net_type = \"alexnet\"\n",
        "if (net_type == 'lenet'):\n",
        "    net = LeNet(outputs,inputs)\n",
        "elif (net_type == 'alexnet'):\n",
        "    net = AlexNet(outputs,inputs)\n",
        "elif (net_type == '3conv3fc'):\n",
        "        net = ThreeConvThreeFC(outputs,inputs)\n",
        "else:\n",
        "    print('Error : Network should be either [LeNet / AlexNet / 3Conv3FC')\n",
        "\n",
        "#print(net)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 26.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6N6CTLupSvs",
        "colab_type": "code",
        "outputId": "0c2a939e-110a-473f-ee72-a5824cfcc8da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# move tensors to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    net.cuda()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 7.37 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hRGdG8UpSyH",
        "colab_type": "code",
        "outputId": "547a40ee-ee1c-4910-dbee-e8de184c3bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.03 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_r9G3cKpS0Z",
        "colab_type": "code",
        "outputId": "2f3de8d4-23f1-4111-ad52-1883a25bb082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ckpt_name = f'model_{net_type}_{dataset}_frequentist.pt'\n",
        "ckpt_name"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_alexnet_MNIST_frequentist.pt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.48 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2dB2GZApS25",
        "colab_type": "code",
        "outputId": "d7be5e27-f73e-41af-dccc-e053dcef8b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "%%time\n",
        "import random\n",
        "torch.manual_seed(12)\n",
        "torch.cuda.manual_seed(12)\n",
        "np.random.seed(12)\n",
        "random.seed(12)\n",
        "\n",
        "torch.backends.cudnn.deterministic=True\n",
        "\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "val_correct = 0\n",
        "val_total = 0\n",
        "\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    net.train()\n",
        "    for data, target in train_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = net(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        pred = torch.max(output, dim=1)[1]\n",
        "        correct += torch.sum(pred.eq(target)).item()\n",
        "        total += target.numel()\n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    net.eval()\n",
        "    for data, target in valid_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = net(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        #validation accuracy\n",
        "        _, predicted = output.max(1)\n",
        "        val_correct += predicted.eq(target).sum().item()\n",
        "        val_total += target.size(0)\n",
        "        \n",
        "        \n",
        "\n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    print('Training Accuracy: {:.3f} \\tValidation Accuracy: {:.3f}'.format(\n",
        "        100.*correct/total, 100.*val_correct/val_total))\n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(net.state_dict(), ckpt_name)\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-73f4d7d147a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"import random\\ntorch.manual_seed(12)\\ntorch.cuda.manual_seed(12)\\nnp.random.seed(12)\\nrandom.seed(12)\\n\\ntorch.backends.cudnn.deterministic=True\\n\\n\\n\\ncorrect = 0\\ntotal = 0\\nval_correct = 0\\nval_total = 0\\n\\nvalid_loss_min = np.Inf # track change in validation loss\\n\\nfor epoch in range(1, n_epochs+1):\\n\\n    # keep track of training and validation loss\\n    train_loss = 0.0\\n    valid_loss = 0.0\\n    \\n    ###################\\n    # train the model #\\n    ###################\\n    net.train()\\n    for data, target in train_loader:\\n        # move tensors to GPU if CUDA is available\\n        if use_cuda:\\n            data, target = data.cuda(), target.cuda()\\n        # clear the gradients of all optimized variables\\n        optimizer.zero_grad()\\n        # forward pass: compute predicted outputs by passing inputs to the model\\n        output = net(data)\\n        # calculate the batch loss\\n        loss = criterion(output, target)\\n        # backward pass: compute gradient of the loss with respect to model parameters\\n        loss.backward()\\n        # perform a single optimization step (parameter update)\\n        optimizer.step()\\n        # update training loss\\n        train_loss += loss.item()*data.size(0)\\n        pred = torch.max(output, dim=1)[1]\\n        correct += torch.sum(pred.eq(target)).it...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-33c53f92c3f4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 64 3 11 11, expected input[32, 1, 28, 28] to have 3 channels, but got 1 channels instead"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "time: 82.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C00M5_MopeYX",
        "colab_type": "code",
        "outputId": "3e0ad62e-36de-4620-9722-9c284bb63734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net.load_state_dict(torch.load(ckpt_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voR3aqETpgKb",
        "colab_type": "code",
        "outputId": "730b5db6-8c62-433a-c135-29c0350081cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# track test loss# track  \n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for data, target in test_loader:\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if use_cuda:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = net(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not use_cuda else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(batch_size):\n",
        "        if i >= target.data.shape[0]: # batch_size could be greater than left number of images\n",
        "            break\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.137909\n",
            "\n",
            "Test Accuracy of airplane: 76% (767/1000)\n",
            "Test Accuracy of automobile: 73% (736/1000)\n",
            "Test Accuracy of  bird: 31% (312/1000)\n",
            "Test Accuracy of   cat: 41% (418/1000)\n",
            "Test Accuracy of  deer: 64% (645/1000)\n",
            "Test Accuracy of   dog: 54% (545/1000)\n",
            "Test Accuracy of  frog: 77% (776/1000)\n",
            "Test Accuracy of horse: 70% (705/1000)\n",
            "Test Accuracy of  ship: 73% (739/1000)\n",
            "Test Accuracy of truck: 69% (693/1000)\n",
            "\n",
            "Test Accuracy (Overall): 63% (6336/10000)\n",
            "CPU times: user 1.92 s, sys: 129 ms, total: 2.05 s\n",
            "Wall time: 2.05 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}