{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Occam factor Bayesian CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6AQVvqwKbM5",
        "colab_type": "text"
      },
      "source": [
        "# Occam factor for a Bayesian CNN\n",
        "\n",
        "- Conceptualizing and illustrating David MacKay's Occam Factor [1] for a Bayesian LeNet CNN with variational inference [2].\n",
        "\n",
        "[1] *MacKay, David. \"Bayesian Methods for Adaptive Models.\" PhD diss., California Institute of Technology, 1992.*\n",
        "\n",
        "[2] *Shridhar, Kumar, Felix Laumann, and Marcus Liwicki. \"A Comprehensive Guide to Bayesian Convolutional Neural Network with Variational Inference.\" arXiv preprint arXiv:1901.02731, 2019.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpvCIGQyKaBt",
        "colab_type": "code",
        "outputId": "9e5fa2da-c8ef-4429-e22a-2eb6cdce2a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "#!git clone https://github.com/kumar-shridhar/PyTorch-BayesianCNN.git\n",
        "\n",
        "@article{shridhar2019comprehensive,\n",
        "  title={A comprehensive guide to bayesian convolutional neural network with variational inference},\n",
        "  author={Shridhar, Kumar and Laumann, Felix and Liwicki, Marcus},\n",
        "  journal={arXiv preprint arXiv:1901.02731},\n",
        "  year={2019}\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch-BayesianCNN'...\n",
            "remote: Enumerating objects: 296, done.\u001b[K\n",
            "remote: Counting objects: 100% (296/296), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 1287 (delta 159), reused 248 (delta 115), pack-reused 991\u001b[K\n",
            "Receiving objects: 100% (1287/1287), 67.74 MiB | 9.84 MiB/s, done.\n",
            "Resolving deltas: 100% (760/760), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awxW6jgHKlG-",
        "colab_type": "code",
        "outputId": "0b0b8cca-9b05-4b7a-f7cd-03adfc9d1977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "%cd /content/PyTorch-BayesianCNN\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PyTorch-BayesianCNN\n",
            "config_bayesian.py     layers\t\t    models\n",
            "config_frequentist.py  LICENSE\t\t    README.md\n",
            "data\t\t       main_bayesian.py     tests\n",
            "experiments\t       main_frequentist.py  utils.py\n",
            "__init__.py\t       metrics.py\t    visualize_mean_var.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1kTwOJAKoGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# in order to run this script, you will need to downgrade torchvision and pillow:\n",
        "import PIL\n",
        "import torch, torchvision\n",
        "if torchvision.__version__ == \"0.5.0\":\n",
        "  !pip install torchvision==0.4.2\n",
        "if PIL.__version__ == \"7.0.0\":\n",
        "  !pip install pillow==6.2.0\n",
        "\n",
        "print(torchvision.__version__)\n",
        "print(PIL.__version__)\n",
        "# for tracking  cell run times\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdIN2agOvXVK",
        "colab_type": "text"
      },
      "source": [
        "# Occam factor approximated by sampled weights\n",
        "\n",
        "As in MacKay's second level of inference, we can compute an approximation of the Occam factor by sampling 2 weights (one random FC weight and one random filter weight), and computing the ratio of the weight's posterior standard deviation to its prior standard deviation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjMoyKcyuHOl",
        "colab_type": "code",
        "outputId": "7e4dd40a-2683-4cf3-a63b-6f27e253b685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.optim import Adam\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import data\n",
        "import utils\n",
        "import metrics\n",
        "import config_bayesian as cfg\n",
        "from models.BayesianModels.Bayesian3Conv3FC import BBB3Conv3FC\n",
        "from models.BayesianModels.BayesianAlexNet import BBBAlexNet\n",
        "from models.BayesianModels.BayesianLeNet import BBBLeNet\n",
        "\n",
        "# CUDA settings\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#how many epochs to train the model for?\n",
        "N_EPOCHS = 30\n",
        "#how many times to train each model? Set equal to 1 to retrieve plots of the weight densities\n",
        "N_MODELS = 15\n",
        "\n",
        "\n",
        "\n",
        "def getModel(net_type, inputs, outputs):\n",
        "    if (net_type == 'lenet'):\n",
        "        return BBBLeNet(outputs,inputs)\n",
        "    elif (net_type == 'alexnet'):\n",
        "        return BBBAlexNet(outputs, inputs)\n",
        "    elif (net_type == '3conv3fc'):\n",
        "        return BBB3Conv3FC(outputs,inputs)\n",
        "    else:\n",
        "        raise ValueError('Network should be either [LeNet / AlexNet / 3Conv3FC')\n",
        "\n",
        "def calc_uncertainty_softmax(output):\n",
        "    prediction = F.softmax(output, dim = 1)\n",
        "    #print(prediction)\n",
        "    results = torch.max(prediction, 1 )\n",
        "    #print(results)\n",
        "    p_hat = np.array(results[0].cpu().detach())\n",
        "    epistemic = np.mean(p_hat ** 2, axis=0) - np.mean(p_hat, axis=0) ** 2\n",
        "    epistemic += epistemic \n",
        "    #print(epistemic)\n",
        "    aleatoric = np.mean(p_hat * (1-p_hat), axis = 0)\n",
        "    aleatoric += aleatoric\n",
        "    #print (aleatoric)\n",
        "    return epistemic, aleatoric\n",
        "\n",
        "def occam(l):\n",
        "    return l[-1]/l[0]\n",
        "\n",
        "\n",
        "def train_model(net, optimizer, criterion, trainloader, num_ens=10):\n",
        "    \n",
        "    net.train()\n",
        "    training_loss = 0.0\n",
        "    accs = []\n",
        "    kl_list = []\n",
        "    freq = cfg.recording_freq_per_epoch\n",
        "    freq = len(trainloader)//freq\n",
        "    # there are 96 batches\n",
        "    batch_fcW_list = [] #collect sampled weight into batch list\n",
        "    batch_convW_list = []\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 1):\n",
        "        cfg.curr_batch_no = i\n",
        "        if i%freq==0:\n",
        "            cfg.record_now = True\n",
        "        else:\n",
        "            cfg.record_now = False\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = torch.zeros(inputs.shape[0], net.num_classes, num_ens).to(device)\n",
        "\n",
        "        kl = 0.0\n",
        "        for j in range(num_ens):\n",
        "            net_out, _kl = net(inputs)\n",
        "            kl += _kl\n",
        "            outputs[:, :, j] = F.log_softmax(net_out, dim=1)\n",
        "        #for fully connected layer 3:\n",
        "        which_node = 0\n",
        "        which_weight = 0\n",
        "        sampled_fc_weight = net.fc3.W[which_node][which_weight].item()\n",
        "        #for convolutional layer 1 (choose first of everything):\n",
        "        which_filter = 0\n",
        "        which_channel = 0\n",
        "        which_row = 0\n",
        "        which_col = 0\n",
        "        sampled_conv_weight = net.conv1.weight[which_filter][which_channel][which_row][which_col].item()\n",
        "\n",
        "        batch_fcW_list.append(sampled_fc_weight)\n",
        "        batch_convW_list.append(sampled_conv_weight)\n",
        "        kl = kl / num_ens\n",
        "        kl_list.append(kl.item())\n",
        "        log_outputs = utils.logmeanexp(outputs, dim=2)\n",
        "\n",
        "        loss = criterion(log_outputs, labels, kl)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        accs.append(metrics.acc(log_outputs.data, labels))\n",
        "        training_loss += loss.cpu().data.numpy()\n",
        "    average_sampled_fc_weight_across_batches = np.mean(batch_fcW_list)\n",
        "    average_sampled_conv_weight_across_batches = np.mean(batch_convW_list)\n",
        "    print(\"Across all batches, the average of the sampled FC weight is\\t{} and the average of the sampled conv. weight is \\t{}\".format(average_sampled_fc_weight_across_batches, average_sampled_conv_weight_across_batches))\n",
        "    return training_loss/len(trainloader), np.mean(accs), np.mean(kl_list), batch_fcW_list, batch_convW_list\n",
        "\n",
        "\n",
        "def validate_model(net, criterion, validloader, num_ens=1):\n",
        "    \"\"\"Calculate ensemble accuracy and NLL Loss\"\"\"\n",
        "    net.eval()\n",
        "    valid_loss = 0.0\n",
        "    accs = []\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(validloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = torch.zeros(inputs.shape[0], net.num_classes, num_ens).to(device)\n",
        "        kl = 0.0\n",
        "        for j in range(num_ens):\n",
        "            net_out, _kl = net(inputs)\n",
        "            kl += _kl\n",
        "            outputs[:, :, j] = F.log_softmax(net_out, dim=1).data\n",
        "\n",
        "        log_outputs = utils.logmeanexp(outputs, dim=2)\n",
        "        valid_loss += criterion(log_outputs, labels, kl).item()\n",
        "        accs.append(metrics.acc(log_outputs, labels))\n",
        "\n",
        "    return valid_loss/len(validloader), np.mean(accs)\n",
        "\n",
        "def test_model(net, criterion, testloader, num_ens=10):\n",
        "    \"\"\"Calculate ensemble accuracy and NLL Loss\"\"\"\n",
        "    net.eval()\n",
        "    test_loss = 0.0\n",
        "    accs = []\n",
        "    epistemic_list = []\n",
        "    aleatoric_list = []\n",
        "    for i, (inputs, labels) in enumerate(testloader):\n",
        "        #print(i)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = torch.zeros(inputs.shape[0], net.num_classes, num_ens).to(device)\n",
        "        kl = 0.0\n",
        "        VI_epistemics = []\n",
        "        VI_aleatorics = []\n",
        "        for j in range(num_ens):\n",
        "            net_out, _kl = net(inputs)\n",
        "            kl += _kl\n",
        "            outputs[:, :, j] = F.log_softmax(net_out, dim=1).data\n",
        "            #print(net_out.shape)\n",
        "            epistemic , aleatoric = calc_uncertainty_softmax(net_out)\n",
        "            VI_epistemics.append(epistemic)\n",
        "            VI_aleatorics.append(aleatoric)\n",
        "        epistemic_list.append(np.mean(VI_epistemics))\n",
        "        aleatoric_list.append(np.mean(VI_aleatorics))\n",
        "        log_outputs = utils.logmeanexp(outputs, dim=2)\n",
        "        test_loss += criterion(log_outputs, labels, kl).item()\n",
        "        accs.append(metrics.acc(log_outputs, labels))\n",
        "\n",
        "        avg_epistemic_uncertainty = np.round(np.mean(epistemic_list), 5) # across ensembles AND batches\n",
        "        avg_aleatoric_uncertainty =  np.round(np.mean(aleatoric_list), 5)\n",
        "    return test_loss/len(testloader), np.mean(accs), len(accs),  avg_epistemic_uncertainty, avg_aleatoric_uncertainty###return accs\n",
        "\n",
        "\n",
        "def run(dataset, net_type):\n",
        "\n",
        "    # Hyper Parameter settings\n",
        "    train_ens = cfg.train_ens\n",
        "    valid_ens = cfg.valid_ens\n",
        "    lr_start = cfg.lr_start\n",
        "    num_workers = cfg.num_workers\n",
        "    valid_size = cfg.valid_size\n",
        "    batch_size = cfg.batch_size\n",
        "    n_epochs = N_EPOCHS\n",
        "    trainset, testset, inputs, outputs = data.getDataset(dataset)\n",
        "    train_loader, valid_loader, test_loader = data.getDataloader(\n",
        "        trainset, testset, valid_size, batch_size, num_workers)\n",
        "    net = getModel(net_type, inputs, outputs).to(device)\n",
        "    \n",
        "    ckpt_dir = f'saved_model/{dataset}/bayesian' \n",
        "    ckpt_name = f'saved_model/{dataset}/bayesian/model_{net_type}.pt'\n",
        "\n",
        "    if not os.path.exists(ckpt_dir):\n",
        "        os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "    criterion = metrics.ELBO(len(trainset)).to(device)\n",
        "    optimizer = Adam(net.parameters(), lr=lr_start)\n",
        "    valid_loss_max = np.Inf\n",
        "    epoch_fc_weight_list = [] \n",
        "    epoch_conv_weight_list = []\n",
        "    for epoch in range(n_epochs):  \n",
        "        cfg.curr_epoch_no = epoch\n",
        "        utils.adjust_learning_rate(optimizer, metrics.lr_linear(epoch, 0, n_epochs, lr_start))\n",
        "\n",
        "        train_loss, train_acc, train_kl, batch_fcW_list, batch_convW_list = train_model(net, optimizer, criterion, train_loader, num_ens=train_ens)\n",
        "\n",
        "        valid_loss, valid_acc = validate_model(net, criterion, valid_loader, num_ens=valid_ens)\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f} \\tValidation Loss: {:.4f} \\tValidation Accuracy: {:.4f} \\ttrain_kl_div: {:.4f}'.format(\n",
        "            epoch, train_loss, train_acc, valid_loss, valid_acc, train_kl))\n",
        "        # take std dev for the sampled fc and conv weights across the batches, to see if std dev decreases with more training\n",
        "        epoch_fc_weight_list.append(np.std(batch_fcW_list)) \n",
        "        epoch_conv_weight_list.append(np.std(batch_convW_list))\n",
        "       \n",
        "        # save model if validation accuracy has increased\n",
        "        if valid_loss <= valid_loss_max:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                valid_loss_max, valid_loss))\n",
        "            torch.save(net.state_dict(), ckpt_name)\n",
        "            valid_loss_max = valid_loss\n",
        "\n",
        "    return net, criterion, test_loader, ckpt_name, train_acc, epoch_fc_weight_list, epoch_conv_weight_list\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    NET_TYPE = 'lenet'\n",
        "    DATASET = 'MNIST'\n",
        "\n",
        "    parser = argparse.ArgumentParser(description = \"PyTorch Bayesian Model Training\")\n",
        "    parser.add_argument('--net_type', default=NET_TYPE, type=str, help='model')\n",
        "    parser.add_argument('--dataset', default=DATASET, type=str, help='dataset = [MNIST/CIFAR10/CIFAR100]')\n",
        "    parser.add_argument('-f')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if cfg.record_mean_var:\n",
        "        mean_var_dir = f\"graphs_progress/{args.dataset}/bayesian/{args.net_type}/\"\n",
        "        cfg.mean_var_dir = mean_var_dir\n",
        "        if not os.path.exists(mean_var_dir):\n",
        "            os.makedirs(mean_var_dir, exist_ok=True)\n",
        "\n",
        "        for file in os.listdir(mean_var_dir):\n",
        "            os.remove(mean_var_dir + file)\n",
        "\n",
        "    # metrics to track\n",
        "    test_accuracies = []\n",
        "    generalization_gaps = []\n",
        "    fc_occams = []\n",
        "    conv_occams = []\n",
        "    epistemics = []\n",
        "    aleatorics = []\n",
        "    test_losses = []\n",
        "\n",
        "    for j in range(N_MODELS):\n",
        "        net, criterion, test_loader, ckpt_name, train_acc, epoch_fc_weight_list, epoch_conv_weight_list = run(args.dataset, args.net_type)\n",
        "        occam_fc = occam(epoch_fc_weight_list)\n",
        "        occam_conv = occam(epoch_conv_weight_list)\n",
        "        test_loss, test_acc, _, avg_epistemic, avg_aleatoric = test_model(net, criterion, test_loader)\n",
        "        gg = train_acc - test_acc\n",
        "        \n",
        "        test_accuracies.append(test_acc)\n",
        "        generalization_gaps.append(gg)\n",
        "        fc_occams.append(occam_fc)\n",
        "        conv_occams.append(occam_conv)\n",
        "        epistemics.append(avg_epistemic)\n",
        "        aleatorics.append(avg_aleatoric)\n",
        "        test_losses.append(test_loss)\n",
        "    model_number = list(range(1, N_MODELS+1))\n",
        "    # Create a zipped list of tuples from above lists\n",
        "    zippedList =  list(zip(model_number, test_accuracies, generalization_gaps, epistemics, aleatorics, fc_occams, conv_occams, test_losses))\n",
        "    # Create a dataframe from zipped list\n",
        "    dfObj = pd.DataFrame(zippedList, columns = ['Model Number','Test Accuracy' , 'Generalization Gap', 'Avg. Epistemic', 'Avg. Aleatoric', 'Occam factor (FC)', 'Occam factor (Filter)', 'Test Loss']) \n",
        "    directory_to_save_csv = 'result/'\n",
        "    if not os.path.exists(directory_to_save_csv):\n",
        "        os.makedirs(directory_to_save_csv)\n",
        "    file_name = f\"result_dataframe_for_{N_EPOCHS}_epochs.csv\"\n",
        "    dfObj.to_csv(directory_to_save_csv + file_name, index = False, header=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Across all batches, the average of the sampled FC weight is\t-0.053323336062021554 and the average of the sampled conv. weight is \t-0.06760577183592886\n",
            "Epoch: 0 \tTraining Loss: 284545.7026 \tTraining Accuracy: 0.1827 \tValidation Loss: 229890.3913 \tValidation Accuracy: 0.5453 \ttrain_kl_div: 152431.4844\n",
            "Validation loss decreased (inf --> 229890.391276).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.07637279434129596 and the average of the sampled conv. weight is \t0.048975919067743234\n",
            "Epoch: 1 \tTraining Loss: 196356.9867 \tTraining Accuracy: 0.7409 \tValidation Loss: 182015.4818 \tValidation Accuracy: 0.8126 \ttrain_kl_div: 149593.9712\n",
            "Validation loss decreased (229890.391276 --> 182015.481771).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.08863261458463967 and the average of the sampled conv. weight is \t0.09347148138719301\n",
            "Epoch: 2 \tTraining Loss: 174647.6165 \tTraining Accuracy: 0.8469 \tValidation Loss: 169961.3691 \tValidation Accuracy: 0.8685 \ttrain_kl_div: 146868.1582\n",
            "Validation loss decreased (182015.481771 --> 169961.369141).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.09600959089584649 and the average of the sampled conv. weight is \t0.12269812636077404\n",
            "Epoch: 3 \tTraining Loss: 164428.7183 \tTraining Accuracy: 0.8941 \tValidation Loss: 160807.8164 \tValidation Accuracy: 0.9087 \ttrain_kl_div: 144218.2134\n",
            "Validation loss decreased (169961.369141 --> 160807.816406).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.10106139924998085 and the average of the sampled conv. weight is \t0.13330043572932482\n",
            "Epoch: 4 \tTraining Loss: 158004.4194 \tTraining Accuracy: 0.9139 \tValidation Loss: 155826.1491 \tValidation Accuracy: 0.9198 \ttrain_kl_div: 141655.1592\n",
            "Validation loss decreased (160807.816406 --> 155826.149089).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.10349737860572834 and the average of the sampled conv. weight is \t0.138595518656075\n",
            "Epoch: 5 \tTraining Loss: 153570.2378 \tTraining Accuracy: 0.9237 \tValidation Loss: 151476.7871 \tValidation Accuracy: 0.9294 \ttrain_kl_div: 139189.3062\n",
            "Validation loss decreased (155826.149089 --> 151476.787109).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.10744251652310292 and the average of the sampled conv. weight is \t0.14007058770706257\n",
            "Epoch: 6 \tTraining Loss: 149486.7454 \tTraining Accuracy: 0.9336 \tValidation Loss: 147984.9167 \tValidation Accuracy: 0.9333 \ttrain_kl_div: 136822.0465\n",
            "Validation loss decreased (151476.787109 --> 147984.916667).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.11091052919315796 and the average of the sampled conv. weight is \t0.13997936310867468\n",
            "Epoch: 7 \tTraining Loss: 146042.5526 \tTraining Accuracy: 0.9391 \tValidation Loss: 144786.6432 \tValidation Accuracy: 0.9401 \ttrain_kl_div: 134551.8205\n",
            "Validation loss decreased (147984.916667 --> 144786.643229).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.11398875302014251 and the average of the sampled conv. weight is \t0.13880607966954508\n",
            "Epoch: 8 \tTraining Loss: 142623.7783 \tTraining Accuracy: 0.9462 \tValidation Loss: 141460.6569 \tValidation Accuracy: 0.9468 \ttrain_kl_div: 132380.0975\n",
            "Validation loss decreased (144786.643229 --> 141460.656901).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.11679318648142119 and the average of the sampled conv. weight is \t0.13731087076788148\n",
            "Epoch: 9 \tTraining Loss: 139998.7061 \tTraining Accuracy: 0.9479 \tValidation Loss: 139235.9967 \tValidation Accuracy: 0.9466 \ttrain_kl_div: 130309.4360\n",
            "Validation loss decreased (141460.656901 --> 139235.996745).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.11967906930173437 and the average of the sampled conv. weight is \t0.13577644169951478\n",
            "Epoch: 10 \tTraining Loss: 137307.2350 \tTraining Accuracy: 0.9521 \tValidation Loss: 136393.9811 \tValidation Accuracy: 0.9519 \ttrain_kl_div: 128337.8604\n",
            "Validation loss decreased (139235.996745 --> 136393.981120).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.12160738518772025 and the average of the sampled conv. weight is \t0.1334429271519184\n",
            "Epoch: 11 \tTraining Loss: 134883.1289 \tTraining Accuracy: 0.9555 \tValidation Loss: 134102.1797 \tValidation Accuracy: 0.9555 \ttrain_kl_div: 126465.7070\n",
            "Validation loss decreased (136393.981120 --> 134102.179688).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.12259720079600811 and the average of the sampled conv. weight is \t0.13143656682223082\n",
            "Epoch: 12 \tTraining Loss: 132679.3118 \tTraining Accuracy: 0.9578 \tValidation Loss: 131742.0863 \tValidation Accuracy: 0.9574 \ttrain_kl_div: 124690.8541\n",
            "Validation loss decreased (134102.179688 --> 131742.086263).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.12495973302672307 and the average of the sampled conv. weight is \t0.13100395382692417\n",
            "Epoch: 13 \tTraining Loss: 130563.6115 \tTraining Accuracy: 0.9604 \tValidation Loss: 129615.5231 \tValidation Accuracy: 0.9603 \ttrain_kl_div: 123016.1557\n",
            "Validation loss decreased (131742.086263 --> 129615.523112).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.1262814855823914 and the average of the sampled conv. weight is \t0.13081096252426505\n",
            "Epoch: 14 \tTraining Loss: 128671.8542 \tTraining Accuracy: 0.9616 \tValidation Loss: 128253.8822 \tValidation Accuracy: 0.9593 \ttrain_kl_div: 121441.7799\n",
            "Validation loss decreased (129615.523112 --> 128253.882161).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.12892375653609633 and the average of the sampled conv. weight is \t0.12980209973951182\n",
            "Epoch: 15 \tTraining Loss: 126967.4104 \tTraining Accuracy: 0.9627 \tValidation Loss: 126404.6426 \tValidation Accuracy: 0.9628 \ttrain_kl_div: 119963.9825\n",
            "Validation loss decreased (128253.882161 --> 126404.642578).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.12986498046666384 and the average of the sampled conv. weight is \t0.12816005883117518\n",
            "Epoch: 16 \tTraining Loss: 125303.1490 \tTraining Accuracy: 0.9645 \tValidation Loss: 124979.7767 \tValidation Accuracy: 0.9627 \ttrain_kl_div: 118583.4458\n",
            "Validation loss decreased (126404.642578 --> 124979.776693).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.1304157030147811 and the average of the sampled conv. weight is \t0.12522981804795563\n",
            "Epoch: 17 \tTraining Loss: 123772.6578 \tTraining Accuracy: 0.9664 \tValidation Loss: 123326.4346 \tValidation Accuracy: 0.9652 \ttrain_kl_div: 117299.0868\n",
            "Validation loss decreased (124979.776693 --> 123326.434570).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.13178270682692528 and the average of the sampled conv. weight is \t0.12417382110531132\n",
            "Epoch: 18 \tTraining Loss: 122429.1078 \tTraining Accuracy: 0.9668 \tValidation Loss: 122067.0866 \tValidation Accuracy: 0.9653 \ttrain_kl_div: 116111.9419\n",
            "Validation loss decreased (123326.434570 --> 122067.086589).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.13236508735766014 and the average of the sampled conv. weight is \t0.12358321202918887\n",
            "Epoch: 19 \tTraining Loss: 121289.9048 \tTraining Accuracy: 0.9662 \tValidation Loss: 120703.8828 \tValidation Accuracy: 0.9667 \ttrain_kl_div: 115020.9038\n",
            "Validation loss decreased (122067.086589 --> 120703.882812).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.13321583066135645 and the average of the sampled conv. weight is \t0.12260089325718582\n",
            "Epoch: 20 \tTraining Loss: 119900.7527 \tTraining Accuracy: 0.9684 \tValidation Loss: 119757.5928 \tValidation Accuracy: 0.9664 \ttrain_kl_div: 114026.8877\n",
            "Validation loss decreased (120703.882812 --> 119757.592773).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.1341006082172195 and the average of the sampled conv. weight is \t0.12294964616497357\n",
            "Epoch: 21 \tTraining Loss: 118801.0574 \tTraining Accuracy: 0.9689 \tValidation Loss: 118743.9014 \tValidation Accuracy: 0.9644 \ttrain_kl_div: 113126.9248\n",
            "Validation loss decreased (119757.592773 --> 118743.901367).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.13462788828959069 and the average of the sampled conv. weight is \t0.12227491638623178\n",
            "Epoch: 22 \tTraining Loss: 118026.4036 \tTraining Accuracy: 0.9698 \tValidation Loss: 117756.7992 \tValidation Accuracy: 0.9693 \ttrain_kl_div: 112323.4054\n",
            "Validation loss decreased (118743.901367 --> 117756.799154).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.13582306106885275 and the average of the sampled conv. weight is \t0.12160772869052987\n",
            "Epoch: 23 \tTraining Loss: 117095.7417 \tTraining Accuracy: 0.9711 \tValidation Loss: 117159.5879 \tValidation Accuracy: 0.9663 \ttrain_kl_div: 111614.4989\n",
            "Validation loss decreased (117756.799154 --> 117159.587891).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.13702862973635396 and the average of the sampled conv. weight is \t0.12146555089081328\n",
            "Epoch: 24 \tTraining Loss: 116345.6191 \tTraining Accuracy: 0.9718 \tValidation Loss: 116450.8291 \tValidation Accuracy: 0.9707 \ttrain_kl_div: 111000.5946\n",
            "Validation loss decreased (117159.587891 --> 116450.829102).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.13777352310717106 and the average of the sampled conv. weight is \t0.12170319266927739\n",
            "Epoch: 25 \tTraining Loss: 115753.7048 \tTraining Accuracy: 0.9719 \tValidation Loss: 115704.5553 \tValidation Accuracy: 0.9707 \ttrain_kl_div: 110481.4204\n",
            "Validation loss decreased (116450.829102 --> 115704.555339).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.1379459222468237 and the average of the sampled conv. weight is \t0.12244218254151444\n",
            "Epoch: 26 \tTraining Loss: 115297.2757 \tTraining Accuracy: 0.9726 \tValidation Loss: 115386.5439 \tValidation Accuracy: 0.9708 \ttrain_kl_div: 110056.4382\n",
            "Validation loss decreased (115704.555339 --> 115386.543945).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.13826902257278562 and the average of the sampled conv. weight is \t0.12235280374685924\n",
            "Epoch: 27 \tTraining Loss: 114744.7240 \tTraining Accuracy: 0.9734 \tValidation Loss: 114971.0954 \tValidation Accuracy: 0.9712 \ttrain_kl_div: 109725.6449\n",
            "Validation loss decreased (115386.543945 --> 114971.095378).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.13876205512012044 and the average of the sampled conv. weight is \t0.12208471447229385\n",
            "Epoch: 28 \tTraining Loss: 114562.0533 \tTraining Accuracy: 0.9730 \tValidation Loss: 114813.2419 \tValidation Accuracy: 0.9714 \ttrain_kl_div: 109489.3018\n",
            "Validation loss decreased (114971.095378 --> 114813.241862).  Saving model ...\n",
            "Across all batches, the average of the sampled FC weight is\t-0.139041130275776 and the average of the sampled conv. weight is \t0.12187459343113005\n",
            "Epoch: 29 \tTraining Loss: 114328.7743 \tTraining Accuracy: 0.9731 \tValidation Loss: 114591.8936 \tValidation Accuracy: 0.9720 \ttrain_kl_div: 109347.2359\n",
            "Validation loss decreased (114813.241862 --> 114591.893555).  Saving model ...\n",
            "time: 6min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlNU3WMConCq",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing the Occam factor \n",
        "\n",
        "- By graphing the reduction in standard deviation of the filter and fully-connected weights separately, we can get an insight into their nature during the updating of the variational posterior.\n",
        "\n",
        "- The Occam factor can be approximated by "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq8c8M0urYLs",
        "colab_type": "code",
        "outputId": "d0b41e46-76b8-49d0-9c87-14aadb411100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "#fully connected weight\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epoch_fc_weight_list)\n",
        "plt.ylabel('Std. Dev. of weight 1 in FC3')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()\n",
        "of_fc = epoch_fc_weight_list[-1]/epoch_fc_weight_list[0]\n",
        "print(\"Occam factor is: \\t{}\".format(of_fc)) \n",
        "\n",
        "#convolutional weight\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epoch_conv_weight_list)\n",
        "plt.ylabel('Std. Dev. of weight 1 in Conv1')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()\n",
        "of_conv = epoch_conv_weight_list[-1]/epoch_conv_weight_list[0]\n",
        "print(\"Occam factor is: \\t{}\".format(of_conv)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU9dX48c/JHiAbEJKwBgVEQGQJ4EpdqqVWxVoXQPuopbXWve3Tp619ftba2qpd3OryqNi6I3WlFsUFFTeQgMgqiCwCCSEsmayTZCbn98fcwRiTyWSSyWRmzvv1yit3vnPvzbmdOofvLqqKMcYY01EJkQ7AGGNMdLIEYowxJiSWQIwxxoTEEogxxpiQWAIxxhgTkqRIB9Ad+vfvr4WFhZEOwxhjosbKlSv3qWpuoHPiIoEUFhZSXFwc6TCMMSZqiMiO9s6xJixjjDEhsQRijDEmJJZAjDHGhMQSiDHGmJBYAjHGGBMSSyDGGGNCYgnEGGNMSCyBdIF91fUsWlsa6TCMMaZbWQLpAk8u+4Irn1xFRW1DpEMxxphuYwmkC+yuqAWg1OWOcCTGGNN9LIF0AX/i2FNpCcQYEz8sgXSBkoo6APZYDcQYE0csgXSSqn5ZA7EEYoyJI5ZAOqmyzkNtgxewBGKMiS+WQDqpxFV36Nj6QIwx8cQSSCeVOgmkf59Uq4EYY+KKJZBOKqnwJY1JQ7MPJRNjjIkHlkA6qdRVR1KCMH5wFpVuD7UNnkiHZIwx3cISSCeVVrjJy0xjYHY6YB3pxpj4EdYEIiIzRGSTiGwRkV+18n6qiDzjvL9cRAqbvfdrp3yTiHyrWfl2EVkrIqtFJOIbnZe46ijISiM/Kw2wjnRjTPwIWwIRkUTgXuDbwBhgtoiMaXHaXOCgqo4A7gBuc64dA8wCxgIzgPuc+/mdrKoTVLUoXPEHq9TlpiA7nfxMJ4FYDcQYEyfCWQOZCmxR1a2q2gDMB2a2OGcm8Khz/CxwqoiIUz5fVetVdRuwxblfj9LUpJRWuBnYrAZi62EZY+JFOBPIIGBns9e7nLJWz1FVD+AC+rVzrQKvichKEbm8rT8uIpeLSLGIFJeXl3fqQdqyv6aBBm8TBVlp9EpJIis9mTJrwjLGxIlo7EQ/QVUn4Wsau0pEprd2kqo+qKpFqlqUm5sblkD8w3YLnA70/Mw0q4EYY+JGOBPIbmBIs9eDnbJWzxGRJCAL2B/oWlX1/94LvEAEm7b8c0AGZjkJJCvNaiDGmLgRzgSyAhgpIsNFJAVfp/jCFucsBC5xjs8DlqiqOuWznFFaw4GRwEci0ltEMgBEpDdwOrAujM8Q0Jc1EF//h9VAjDHxJClcN1ZVj4hcDSwGEoFHVHW9iNwMFKvqQmAe8LiIbAEO4EsyOOctADYAHuAqVfWKSB7wgq+fnSTgKVV9NVzP0J5Sl5uUpAT69U4BfDWQfdX1NHqbSE6MxtZBY4wJXtgSCICqLgIWtSi7sdmxGzi/jWtvAW5pUbYVOLrrIw1NSYVvDoiT0MjPSkMV9lbVM8jpFzHGmFhl/0zuhFKX+1D/B/DlZEJbE8sYEwcsgXRCaUXdof4PgIJDCaQ+UiEZY0y3sQQSIm+TUlZV/9UaSKZ/MqHVQIwxsc8SSIj2VrnxNulXaiBZ6cmkJSfYUF5jTFywBBKilnNAAETEhvIaY+KGJZAQtZwD4peflWYLKhpj4oIlkBCVOjWQgqyvDtctyEq3Jd2NMXHBEkiISlx19E5JJDPtq1Np8jJ9y5k0NWmEIjPGmO5hCSREpRW+fUD8kwj9CrLSaPQqB2obIhSZMcZ0D0sgISp1diJsKc82ljLGxAlLICEqaTEL3a/ANpYyxsQJSyAhqPd4Ka+q/9oILGg2G9060o0xMa7NBCIi+SJyv4jcKyL9ROQmEVkrIgtEpKA7g+xpypylSlqrgfTrk0pigth6WMaYmBeoBvJPfMup7wTeAuqAM4B3gQfCHlkPVtLGHBCAxAQhLyPV1sMyxsS8QAkkT1XvUdVbgWxVvU1Vd6rqPcCwboqvRzo0ibCVGghAXlYaeyqtBmKMiW2BEkjz9x7rwHUx79AyJq3UQMDXD2KjsIwxsS5QInhJRPoAqOr/+gtFZASwOdyB9WSlrjqy0pPpldL6flz5memUutz4duc1xpjY1GYCUdUbVbW6lfItqnpeeMPq2Uor3AwMsONgflYqtQ1equo93RiVMcZ0r0CjsH4mInNbKZ8rIteHN6yezTcHpPXmK4B8p2+kzJqxjDExLFAT1kV8ve8D4HHgB+EJJzqUuupaHYHl9+XGUpZAjDGxK1ACSVLVxpaFqtoASCvnx4W6Bi8VtY1tjsACm0xojIkPAUdhiUhey8LWyuKJfw5IWyOwAAZkpgK2HpYxJrYFSiB/Bv4jIt8QkQzn5yTgZeAv3RJdD9TWPiDNpSYl0q93ijVhGWNiWuvjUAFVfUxEyoGbgXGAAuuBG1X1lW6Kr8c5VAMJkEDAtzOh7Y1ujIllbSYQACdRxG2yaI2/BpKXlRrwvPzMNEqsBmKMiWGBhvG+1uz4190TTs9X6qqjf59UUpMSA55nNRBjTKwL1AeS2+z4/HAHEi1KXO6AHeh++ZlpHKhpwN3o7YaojDGm+wVKILYORytKK1rfibClfOecvZW2Kq8xJjYF6gM5TEQW4pvz4T8+RFXPDmtkPVSpy83xI/q3e55/lFapq46h/XqFOyxjjOl2gRLIzGbHIQ3bFZEZwF1AIvCwszR88/dT8c12nwzsBy5U1e3Oe78G5gJe4FpVXdzsukSgGNitqmeGElsoKt2NVNd7gmvCcjrZbTKhMSZWBRrG+05nbux8yd8LnAbsAlaIyEJV3dDstLnAQVUdISKzgNuAC0VkDDALGAsMBN4QkVGq6u9QuA7YCGR2JsaOCmYOiJ9/PSybTGiMiVXh3NdjKrBFVbc6y5/M56u1GpzXjzrHzwKniog45fNVtV5VtwFbnPshIoOB7wAPhzH2VpVUtD8L3a9PahJ9UpNsMqExJmaFM4EMwrcdrt8up6zVc1TVA7iAfu1ceyfwP0BToD8uIpeLSLGIFJeXl4f6DF9R0s5OhC3ZUF5jTCyLqp0FReRMYK+qrmzvXFV9UFWLVLUoNze3vdODUlrhJkFgQEbgSYR+BVlpVgMxxsSsgDPRAURkFPALfPugHzpfVU9p59LdwJBmrwc7Za2ds0tEkoAsfJ3pbV17NnC2iJwBpAGZIvKEql7c3nN0hRJXHfmZaSQlBpd38zLT+KxsX5ijMsaYyGg3gQD/Ah4AHsI3IipYK4CRIjIc35f/LGBOi3MWApcAHwLnAUtUVZ0hw0+JyN/wdaKPBD5S1Q+BXwM4Czv+d3clD/DVQAoC7ETYUkFWGuXV9Xi8TUEnHWOMiRbBJBCPqt7f0RurqkdErgYW4xvG+4iqrheRm4FiVV0IzAMeF5EtwAF8SQbnvAXABsADXNVsBFbElLrqGDcoK+jz8zLT8DYp+6obDk0sNMaYWBFMAvm3iFwJvAAcmlatqgfau1BVFwGLWpTd2OzYTRvLpKjqLcAtAe79NvB2ezF0FVWl1OXm9LH5QV/TfGMpSyDGmFgTTAK5xPn9i2ZlChzW9eH0XAdqGqj3NAW1jImfP2nscdXBkOxwhWaMMRHRbgJR1eHdEUhP5x9NFewQXvhyb3SbTGiMiUVtJhAROUVVl4jIua29r6rPhy+snqcjkwj9+vZOISUxgVKbC2KMiUGBaiDfAJYAZ7XyngJxlUBCqYGICHlZqVYDMcbEpEBrYf3W+X1Z94XTc5W46khJTKBf75QOXVeQmW4JxBgTk2xyQpBKK3wjqRISpEPX5Wel2Yq8xpiYZAkkSKWu4DaSaik/K409Ljeqtj+XMSa2WAIJUkmFm4EdmIXul5+ZRr2niYraxjBEZYwxkRNSAhGR07o6kJ7M26SUVbpDroEAtqiiMSbmhFoDmdelUfRw+6rr8TRph9bB8vMnEFvW3RgTawLNA1nY1lv49uyIG4fmgIRQAymwGogxJkYFmgdyInAxUN2iXHB2B4wXocwB8cvtk0qC2N7oxpjYEyiBLANqW9sbXUQ2hS+knsdfAxkUQhNWUmICuRmpvvWwjDEmhgSaSPjtAO9ND084PVNJhZteKYlkpgez9uTX5WfazoTGmNhjw3iD4J8DItKxSYR+tje6MSYWWQIJQokrtDkgflYDMcbEIksgQSitCG0Wul9+VjpVbg819Z4ujMoYYyKr3QQiItcFUxarGjxNlFfXhzQCy6/5zoTGGBMrgqmBXNJK2aVdHEePVVbpRrVj+4C0lOdsLFVmzVjGmBgSaCLhbGAOMLzFpMIMoN390GNFZ+aA+NlkQmNMLAo0LvUDoBToD/y1WXkVsCacQfUkpa6O70TYUr41YRljYlCgeSA7gB3Asd0XTs9TUtH5GkhaciLZvZJtYyljTEwJphP9XBH5TERcIlIpIlUiUtkdwfUEpa46MtOS6J0a2iRCPxvKa4yJNcF8K94OnKWqG8MdTE8U6j4gLdlkQmNMrAlmFFZZvCYPCH0nwpYKsqwGYoyJLYFGYZ3rHBaLyDPAi0C9/31VfT7MsfUIpS43Rw/J7vR98jLT2FddT4OniZQkm79pjIl+gZqwzmp2XAuc3uy1AjGfQNyNXg7UNIS0D0hL/lrM3io3g3N6dfp+xhgTaYFGYV3WnYH0RF0xB8Qv37nHHpclEGNMbGi3E11E7m6l2AUUq+pL7Vw7A7gLSAQeVtVbW7yfCjwGTAb2Axeq6nbnvV8DcwEvcK2qLhaRNGApkOrE/qyq/ra9ZwhVqbMPSEEn5oD45WfaXBBjTGwJpjE+DZgAfOb8jAcGA3NF5M62LhKRROBe4NvAGGC2iIxpcdpc4KCqjgDuAG5zrh0DzALGAjOA+5z71QOnqOrRTkwzROSYIJ+1w0qcGkgoG0m1dGgyoXWkG2NiRDDDeMcDx6uqF0BE7gfeBU4A1ga4biqwRVW3OtfNB2YCG5qdMxO4yTl+Fvi7+DbdmAnMV9V6YJuIbAGmquqHfLnFbrLzo0E8Q0j8NZD8LugDyUxLIj050RKIMSZmBFMDyQH6NHvdG+jrJJT61i8BYBCws9nrXU5Zq+eoqgdf01i/QNeKSKKIrAb2Aq+r6vLW/riIXC4ixSJSXF5eHvgJ21DiqqN/nxRSkxJDur5FPL6hvNaEZYyJEcEkkNuB1SLyDxH5J/Ax8GcR6Q28Ec7gWqOqXlWdgK8ZbaqIjGvjvAdVtUhVi3Jzc0P6WyUV7i7pQPfLz0qzGogxJma0m0BUdR5wHL55IC8AJ6jqw6pao6q/CHDpbmBIs9eDnbJWzxGRJCALX2d6u9eqagXwFr4+krDoqkmEfvmZlkCMMbGjzQQiIqOd35OAAnxNSjuBfKesPSuAkSIyXERS8HWKL2xxzkK+3G/kPGCJqqpTPktEUkVkODAS+EhEckUk24krHTgN+DS4R+240i5axsTPv5xJU1PYum2MMabbBOpE/xlwOV9dyt1PgVMC3VhVPSJyNbAY3zDeR1R1vYjcjG8I8EJgHvC400l+AF+SwTlvAb4Odw9wlap6RaQAeNQZkZUALFDVlzvwvEFralJ+dvooRudndtk987PS8DQp+2sayM1I7bL7GmNMJIjvH/yxraioSIuLiyMdBq+t38Plj6/k31efwFGDsyIdjjHGtElEVqpqUaBzglnOvZeI/K+IPOi8HikiZ3ZVkPHE3yHv36TKGGOiWTCjsP4BNODrSAdfZ/YfwhZRDMvL8jVb2bLuxphYEEwCOVxVbwcaAVS1FpCwRhWj+vdOJSUxgV0HrQZijIl+wSSQBmfEkwKIyOEEnkBo2pCQIBw5MJOPd1ZEOhRjjOm0YBLITcCrwBAReRJ4E/ifcAYVy4qG5fDJzgoaPE2RDsUYYzolmImErwHnApcCTwNFqvp2eMOKXUXDcqj3NLGhNG62lTfGxKhgRmE9gS+BfK6qL6vqvvCHFbsmD8sBoHj7gQhHYowxnRNME9Y8fDPR7xGRrSLynIhcF+a4YtaAzDSG9E1n5Y6DkQ7FGGM6pd3l3FX1LRFZCkwBTgauwLdPx11hji1mFQ3ry3tb9qGq+FavN8aY6BNME9abwPvAhcAmYIqqjg53YLFs8rAcyqvq2XnAhvMaY6JXME1Ya/BNJByHb3Opcc6wXhOiokKnH2SH9YMYY6JXMKOwfqqq0/F1pO/HNzPdJjJ0wsgBGWSkJlk/iDEmqrXbB+KsqHsiMBnYDjyCb0tbE6LEBGHisBxLIMaYqBbMnuhpwN+Alc62s6YLFA3L4Y43NuOqayQrPTnS4RhjTIcF04T1F1VdbsmjaxUNy0EVPv7CaiHGmOgUTCe6CYMJQ7NJTBBrxjLGRK1AW9ralnlh1CsliTEFmRRvtwRijIlOgWogHwKIyOPdFEvcmTwsh9U7K/B4bWFFY0z0CZRAUkRkDnCciJzb8qe7Aoxlk4flUNfoZWNpVaRDMcaYDgs0CusK4CIgGzirxXsKPB+uoOJF8wmFtke6MSbatJlAVPU94D0RKVbVed0YU9woyEpnUHY6xTsOctnxwyMdjjHGdEgw80AeF5FrgenO63eAB1S1MXxhxY/Jw3L4aNsBW1jRGBN1ghnGex++Wej3OT+TgPvDGVQ8KSrMYU+lm90VtrCiMSa6BFMDmaKqRzd7vUREPglXQPFm0lBfP8jKHQcZnNMrwtEYY0zwgqmBeEXkcP8LETkM8IYvpPgyOj+D3imJNqHQGBN1gqmB/AJ4S0S2AgIMAy4La1RxJCkxgYlDc2xCoTEm6gSzI+GbIjISOMIp2qSq9eENK75MHpbDPUs+o7reQ5/UYHK6McZEXlBrYalqvaqucX4seXSxosIcmmxhRWNMlAnrYooiMkNENonIFhH5VSvvp4rIM877y0WksNl7v3bKN4nIt5yyISLylohsEJH1InJdOOPvLhOGZJMgWDOWMSaqhC2BiEgicC/wbWAMMFtExrQ4bS5wUFVHAHcAtznXjgFmAWOBGcB9zv08wM9VdQxwDHBVK/eMOhlpyRyRn2kd6caYqBLOGshUYIuqblXVBmA+MLPFOTOBR53jZ4FTxTebbiYw32k62wZsAaaqaqmqrgJQ1SpgIzAojM/QbYqG5fDxFwfxNmmkQzHGmKCElEBEZFUQpw0CdjZ7vYuvf9kfOsfZsMoF9AvmWqe5ayKwvI0YLxeRYhEpLi8vDyLcyCoqzKGmwcuneyojHYoxxgSl3QQiIpNalqnq18q6k4j0AZ4DrlfVVr9xVfVBVS1S1aLc3NzuDTAEk4d9OaHQGGOiQTA1kL+KyEYR+b2IjOvAvXcDQ5q9HuyUtXqOiCQBWcD+QNeKSDK+5PGkqsbMisCDstPJz0yzjnRjTNQIZk/0k4GTgXLg/0RkrYj8bxD3XgGMFJHhIpKCr1N8YYtzFgKXOMfnAUtUVZ3yWc4oreHASOAjp39kHrBRVf8WRAxRQ0SYPCzHaiDGmKgR7DyQPap6N749QlYDNwZxjQe4GliMr7N7gaquF5GbReRs57R5QD8R2QL8DPiVc+16YAGwAXgVuEpVvcDxwPeBU0RktfNzRvCP27NNHpbD7oo6Sl22sKIxpudrd9qziBwJXIivhrAPeAb4eTA3V9VFwKIWZTc2O3YD57dx7S3ALS3K3sO3nEpM8m8wtXLHQc4cnx7haIwxJrBgaiCPAAeB01X1JFW9X1X3hjmuuHRkQSbpyYnWD2KMiQrBrIV1rIikA0O7IZ64lpyYwIQh2dYPYoyJCsEM4z0LX7/Hq87rCSLSsjPcdJHJw3LYUFpJTb0n0qEYY0xAwTRh3YRvVnkFgKquBmwD7zCZXJiDt0n5ZGdFpEMxxpiAgkkgjarqalFm622EyaShOYhAsTVjGWN6uGA2n1gvInOARGdfkGuBD8IbVvzKSk9m1IAM6wcxxvR4wdRArsG3Km498DRQCVwfzqDi3eTCHFZ9cZAmW1jRGNODBTMTvVZVf6OqU5y1pX7jzN8wYVI0LIcqt4fNe6siHYoxxrQpYAIRkUtEZJWI1Dg/xSLyX90VXLzyL6xo80GMMT1ZmwlERC7B11T1c2AgvuXU/we4TkS+3z3hxaehfXvRv0+q9YMYY3q0QDWQnwDfVdW3VNWlqhWqugT4HnBV94QXn0SEomE5FO84gG9tSWOM6XkCJZBMVd3estApywxXQMbnpCNy2Xmgjvve/jzSoRhjTKsCDeMNtCSsLRcbZhcUDWH5tgP8efEmBmSkcn7RkPYvMsaYbhQogRwpImtaKRfgsDDFYxwJCcJt3xvPvup6fvX8Wvr3SeXk0QMiHZYxxhwSMIF0WxSmVSlJCdx/8WRmP7iMK59cxVM/msbEoTmRDssYY4AAfSCquiPQT3cGGc/6pCbxyKVTGJCZyg/+uYKt5dWRDskYY4AgdyQ0kZWbkcqjl00lQYT/euQj9lbaPE5jTORZAokShf1784/LpnCgpoFL/7GCKndjpEMyxsQ5SyBRZPzgbO67aBKby6q44omV1Hu8kQ7JGBPHQkogInJTF8dhgnTSEQO4/bzxvL9lP//9rzW24KIxJmKCWc69NSu7NArTIedOGkxZZT23vfopAzJS+X9njol0SMaYOBRSAlHVf3d1IKZjrvjGYZRVupn33jbyM9P40XSbmmOM6V5tJhARuYcAOw+q6rVhicgERUS48cwxlFfVc8uijRysbeCHJx5G394pkQ7NGBMnAvWBFONrqkoDJgGfOT8TAPuW6gESEoS/XnA0Zx89kPve/pzjbn2TmxauZ3dF6CvNlFW6ufetLcy4cyn/eH9bF0ZrjIk10t5qryKyDDhBVT3O62TgXVU9phvi6xJFRUVaXFwc6TDCasveKu5/eysvrd4NwDkTB3HFNw5jxICMdq/1eJt4a1M5z6z4grc2leNtUgZmpVHicvP3ORM5c/zAcIdvjOlhRGSlqhYFPCeIBLIJOFZVDzivc4BlqnpEl0UaZvGQQPx2Hazl4Xe3MX/FF9R7mjh9TB5XnjSCo4dkf+3c7ftqeKZ4J8+t3MXeqnpyM1I5b/JgLigaQkFWGt+ft5xPdrp48kfTmFLYNwJPY4yJlK5KIJcBNwFv4VtIcTrwO1X9Z9eEGX7xlED89lfX8+gH2/nnB9updHs4fkQ/fvKNERQV5vDKulKeWbGTZVsPkJggnHxELhdOGcpJR+SSnPhlq2ZFbQPn3v8BB2oaeO4nx3F4bp8IPpExpjt1SQJxbpQPTHNeLlfVPV0QX7eJxwTiV13v4anlO3j43W3sraonJTGBBm8Tw/r14oKiIZw3eTB5mWltXv/F/lq+e9/79EpN5IUrj6d/n9RujN4YEyldVQN5U1VPba+sjWtnAHcBicDDqnpri/dTgceAycB+4EL/JlYi8mtgLuAFrlXVxU75I8CZwF5VHddeDBDfCcSv3uPl+VW72VBSyRlHFTBteF8SEiSoa1fvrGDWgx9yRH4m8390DOkpiWGO1hgTacEkkEB7oqeJSF+gv4jkiEhf56cQ3/7o7f3xROBe4NvAGGC2iLSc8TYXOKiqI4A7gNuca8cAs4CxwAzgPud+AP90ykwHpCYlMnvqUH5/zjiOPbxf0MkDYMKQbO6eNZE1uyq4dv7HeG32uzGGwMN4f4xvGO9o57f/5yXg70HceyqwRVW3qmoDMB+Y2eKcmcCjzvGzwKkiIk75fFWtV9VtwBbnfqjqUuBAEH/fdKHTx+bz2zPH8PqGMn7/8oYesVe7qvLBln24am1hSWMioc2JhKp6F3CXiFyjqveEcO9BwM5mr3fxZT/K185RVY+IuIB+TvmyFte2W+tpTkQuBy4HGDp0aIcCN6279Pjh7DpYx8PvbWNwTjo/PDFys993HqjlhhfW8u5n+zju8H48MXdah2pVxpjOC9SENUVE8v3JQ0T+S0ReEpG7naatHk1VH1TVIlUtys3NjXQ4MeOGM47k2+PyuWXRRl5ZW9rtf9/jbeLhd7dy+h1LWbXjIGcfPZAPPt/PE8ttjzNjulugtbD+D/gmgIhMB24FrsE3E/1B4Lx27r0bGNLs9WCnrLVzdolIEpCFrzM9mGtNBCQkCHdcOIGyh5Zx/TOrGZCZyuRhX//3hKryxYFa1u2uZO1uF+t2u9hUVsWYgkwumjaUU0YPICmxY4tBbyip5FfPr2HNLhenjh7A788ZR0FWGhV1jfxp0adMH5lLYf/eXfWoxph2tDkKS0Q+UdWjneN7gXJVvcl5vVpVJwS8sS8hbAZOxfflvwKYo6rrm51zFXCUql4hIrOAc1X1AhEZCzyFr99jIPAmMFJVvc51hcDLNgorcg7UNHDufe/jqmvkuZ8cB8C6kkrW7XaxdpeLdSUuqtweAJIThVF5GYzKy+DDz/ezp9JNQVYas6YMZdbUIQGHEQO4G73c9eZnPLh0Kzm9krnp7LF856gCfN1lsMfl5vQ73mFUXgbP/PhYEruxKetgTQOuukYq3Y1U1nmocn95XOlupMrtobKukdoGLxdOHcLJRwzottiM6YxODeMVkXXABKdv4lPgcqcDGxFZF8yXt4icAdyJbxjvI6p6i4jcDBSr6kIRSQMeBybi6xifpapbnWt/A/wA8ADXq+orTvnTwElAf6AM+K2qzgsUhyWQ8Ni+r4bv3vc+B5t1YqckJjC6IINxg7IYNzCLowZlMSq/D6lJvkF0Hm8Tb366lyeW7eDdz/aRmCCcdmQeFx8zjONaGR32wef7uOH5tWzfX8sFRYO54Ywjye719aXYXvh4Fz995hNuOGM0l08/PLwP7nhw6ef8cdGnbb4vAhmpSWSmJ9PgaWJfdT2/+c4YfnB84aHkZ0xP1dkE8hvgDGAfMBSYpKoqIiOAR1X1+K4OOFwsgYTP+hIXL60u4fDc3owdmMWovAxSkoJrmtq+r4anP/qCBcU7OVjbyPD+vZkzdSjnTR5Mggi3LNrAguJdDOvXiz9+9yiOH9G/zXupKlc8sZK3Pi3n5WtPYFRe+2uAdYarrpETbl3C2EGZXFA0hMy0ZDLSfMkiMz2ZzLQkeqckHUqItQ0efvrMahavL+OiaUO56eyxX5n1b0xP0+mJhCJyDFAAvKaqNU7ZKEZYWJUAABK6SURBVKCPqq7qymDDyRJIz+Zu9PLKulKeWPYFK3ccJCUpgd4piVS6PfzwxOFcf+qooCYv7quu5/Q7ljIoO53nrzwurF/Qd73xGXe8sZn/XHsCYwdmBXVNU5Ny++JNPPDO55w4sj9/nzOJrPTksMVoTGd02VIm0c4SSPTYWFrJk8t3UFrh5qenjWLcoOC+nP1eXVfKFU+s4qffHMV13xwZlhir3I0cf+sSpg7vx8OXBPzvq1ULVuzkhhfWUti/N49cMoWh/XqFIUpjOqdTM9GNiYQjCzL5wzlHMe/SKR1OHgAzxhUwc8JA7lnyGet2u8IQITz24Q4q3R6uPXVESNdfMGUIj8+dRnlVPefc9z7F221erIlOlkBMzPnd2WPp2zuFny1YTb3H26X3rqn38PC7WznpiFzGD/76EvnBOvbwfrxw5XFkpScz56HlvPixjVI30ccSiIk52b1SuO1749lcVs0dr3/Wpfd+YtkODtY2cs0pnW8eOyy3Dy9ceRwTh2Zz/TOr+dtrm3rEEjHGBMsSiIlJJ48ewKwpQ3hw6ees3NE1TUR1DV4eencrJ4zoz+RhOV1yz+xeKTw+dxrnTx7M3Uu2cM3TH+Nu7NpakzHhYgnExKzffOdICrLS+fmCT6ht8HT6fk999AX7qhu49tSu7ZxPSUrg9vPG88sZo3l5TSkXP7ycBk9Tl/4NY8LBEoiJWRlpyfz5/PFs31/L7a9u6tS93I1e/u+dz5k2vC9Th3f9UnAiwk9OOpw7L5xA8Y6D3PXm5i7/G+2pdDeydHO5rW5sghZoLSxjot5xh/fn0uMK+ecH2zl9bB7HHd72ZMRAFhTvZG9VPXdeGHAFn047Z+Ig3t+yj/vf/pxTRud1WVNZW3ZX1PHGhjLe2FjGsq37afQqg7LT+b/vTw5pFJyJLzYPxMS8ugYvZ9z9Lu5GL/+64lgG53Rs3kW9x8tJf36bQdnp/OuKY8O+DEmVu5EZd75LcqKw6LoT6ZXSdf/OU1XWl1Ty+oYyXt9QxobSSgAOy+3NaWPyGDswiz8t2siBmgb+dO5RnDtpcJf9bRNdbCKhwxKIWbfbxZyHlpGRlszTPzqmQ5P3nlr+BTe8sJZHfzCVb4zqnq0Blm3dz+yHlnHRtKH84ZyjOnUvj7eJ9z/ff6imUepykyAweVgO3zwyj2+OyePw3D6Hzt9XXc/VT61i2dYDXHpcIb/5zpG27EocsgTisARiwJdELp63nPTkRJ760TEMD2Lp90ZvEyf/5W369UnlxSuP69ZFEP/w8gYefm9bpxKXu9HL5Y+vZOnmctKTE5k+qj/fPDKPU0YPoF+f1Dav83ib+NMrnzLvvW1MLezLvRdNIjej7fNN7LEE4rAEYvw2lFRy8bzlJCUIT/3oGEYM6BPw/AXFO/mfZ9cw75IiTj0yr5ui9HE3ejnrnvdw1TXy2k+nt7oKcXvX//jxlbyzuZzfnjWG2VOHkpbc/ppizb20eje/fG4NWenJ3H/xZCYNDb5P5kBNA/9ZU8JrG8rISk9m7MAsxg7MZOzAzIDJy/QMlkAclkBMc5vLqpjz0HIAnvrRtDZX7vV4m/jm396hd2oSL19zQkSWYF+328U5977Pt48q4J7ZE4O+rt7j5YrHV/LWpnJuPfcoZk0NfVvnDSWV/PiJYspc9dx09ljmTGv7XnUNXl7fWMaLH+9m6eZyPE3K4bm9qfc0setg3aHz8jPTfMlk0JdJZVB2ui1z34NYAnFYAjEtbdlbzZyHluFpUp784TSOLMj82jn+PUYeuHgyM8blRyBKn3ve/Iy/vr6Zu2dP5OyjB7Z7fr3Hy0+eWMWST/fyx+8eFfALP1gVtQ1cO381SzeXM2vKEH43c+xX9nj54PP9vLh6N4vX7aGmwUtBVhpnTxjIORMGHfrftqK2gQ0llawvqWR9iYv1JZV8Xl5Nk/MVlN0rmWOG9+O/vzWKEQPCuxy/aZ8lEIclENOabftqmPPQMuoavTwxd9pXhq16m5TT73iH5MQEFl174tc2uupOHm8T5z3wIdv21bD4+unkZ7W9g2ODp4krn1zJGxv3cst3x3HRtGFdFoe3Sfnb65u4963POXpINv99+ije+rScf68pobyqnoy0JL5zVAEzJwxi2vC+Qf1vVtfgZeMeX1LZUOLi5TWl1DZ4+f4xw/jpN0eR1cuWu48USyAOSyCmLV/sr2X2Q8uocjfy+NxpHD3Et0Divz8p4ZqnP+bvcyZy5vj2/9UfblvLqznj7neZOrwfj142pdWmngZPE1c9tYrXN5Tx+3PG8f1jui55NPfquj38fMFqahq8pCQmcPLoXL47cRAnHTGgw30sLe2vrudvr2/m6Y++ICs9mZ+dNorZU4eSFMIosIM1Dfx7TQn1jU1cclxh0BudGR9LIA5LICaQnQdqmfPwMipqGvnnD6YycUg2M+5aSpPC4uund+se64E89uF2bnxpPX84ZxwXt0gOjd4mrnpyFa9tKOPmmWP5r2MLwxrLjv01rNnlYvrI3LDUEjaWVnLzvzfw4db9HJGXwY1njQm4I6Vfg6eJtzft5blVu1jy6V4avb7vt0lDs7nvoskBa2/mqyyBOCyBmPaUVNQx56FllFfV8/1jC3ngnc+588IJnDNxUKRDO6SpSbnkHx9RvP0gr1x3IoXOMORGbxPXPPUxr67fw01njeHS44dHONKuoaosXl/GHxdt5IsDtZw2Jo/fnHHkoeduft663ZU8t2oXCz8p4UBNA/37pHLOhIF8b/Jgtu2r4Rf/+oT0lETunj0x5NUI4o0lEIclEBOMPS43cx5extbyGob3783rP50eUtNJOJW66vjWHUsZMaAPC358LApc+/THvLJuDzeeOYYfnBAbyaM5d6OXR97fxr1LttDoVS47oZCrTx5BbYOXFz/ezXOrdrG5rJqUxAROG5PH9yYPYvrI3K98dlv2VnHFE6vYWl7NL2eM5vLph9mIr3ZYAnFYAjHB2lvl5obn13LxMcM46YgBkQ6nVS+t3s1181fzs9NGsWlPFf9ZW8r/fudIfnjiYZEOLaz2Vrr58+JN/GvlLjLTkqiu99Ckvuap700ezJlHDQzYnFZd7+GXz67hP2tLmTE2nz+fP56MNOukb4slEIclEBNLVJWrn/qY/6wtBYiL5NHcml0VPLh0K4X9enPupEEclht4Mmhzqsq897bxp1c+ZVjfXjzw/cltzgOKd5ZAHJZATKw5WNPADx5dwZnjBzI3Bputwm351v1c9dTH1NR7uO288UHNr4k3lkAclkCMMS2VVbq56slVFO84yGXHF3LDGbZoZHPBJBDbD8QYE5fyMtN4+vJj+OOijfzj/e2s3eXi/KLBZKWnkN0rmexeyWSlJ5OdnkJackJEO933VdezdHM572wup3j7QcYPzuLCKUM4cWRuRIeZWw3EGBP3Xlq9mxueX0tNQ+v70ackJZCd7ksq2ekpZKYnk5mWRGZ6MhlpSWSmJZOZnkRGWjKZaU6Zc05Or5QOr2TgbVJW7zzI25t8SWPtbheq0K93CkWFOazYfpADNQ0Myk7n/KLBnF80hEHZ6V3xP8Uh1oTlsARijGmPu9HL/poGKmobcNU2UlHXiKuukYraRirqnLJap6yukSp3I5V1jVTVewj0NZqUIAzISCUvK438zDTyMtPIb+W4qr6RdzaV8/bmct77bB+uukYSBCYOzeGkUbmcdMQAxg7MJCFBaPA08fqGMuav+IL3tuwDYPrIXGZPHcIpo/O6ZNa9JRCHJRBjTLg0NSk1DR4q3R4nqXicxNKIq7aRvVX17Kl0U1bpZo/LTVllPdX1njbvl5uRyjdG5XLSEbmcMKJ/u8v47zxQy79W7uJfxTspdbnp3yeF700azAVThnxlo7COingCEZEZwF1AIvCwqt7a4v1U4DFgMrAfuFBVtzvv/RqYC3iBa1V1cTD3bI0lEGNMT1Jd73GSiS+p7Kl0k5ggnDCiP2MKMkNavNPbpCzdXM78FV/w5sa9eJqUacP78tjcqYdWTu6IiHaii0gicC9wGrALWCEiC1V1Q7PT5gIHVXWEiMwCbgMuFJExwCxgLDAQeENERjnXtHdPY4zp0fqkJjFiQJ92NzTriMQE4eTRAzh59AD2Vrl5ftVutu+rCSl5BCuco7CmAltUdSuAiMwHZgLNv+xnAjc5x88CfxffUIeZwHxVrQe2icgW534EcU9jjIlrAzLSuOIbh4f974Rz0PMgYGez17ucslbPUVUP4AL6Bbg2mHsCICKXi0ixiBSXl5d34jGMMca0JmZnzajqg6papKpFubm5kQ7HGGNiTjgTyG5gSLPXg52yVs8RkSQgC19nelvXBnNPY4wx3SCcCWQFMFJEhotICr5O8YUtzlkIXOIcnwcsUd+wsIXALBFJFZHhwEjgoyDvaYwxphuErRNdVT0icjWwGN+Q20dUdb2I3AwUq+pCYB7wuNNJfgBfQsA5bwG+znEPcJWqegFau2e4nsEYY0zbbCKhMcaYrwlmHkjMdqIbY4wJL0sgxhhjQhIXTVgiUg7sCPHy/sC+Lgwn0mLteSD2ninWngdi75li7Xng6880TFUDzoGIiwTSGSJS3F47YDSJteeB2HumWHseiL1nirXngdCeyZqwjDHGhMQSiDHGmJBYAmnfg5EOoIvF2vNA7D1TrD0PxN4zxdrzQAjPZH0gxhhjQmI1EGOMMSGxBGKMMSYklkDaICIzRGSTiGwRkV9FOp6uICLbRWStiKwWkahc20VEHhGRvSKyrllZXxF5XUQ+c37nRDLGjmjjeW4Skd3O57RaRM6IZIwdISJDROQtEdkgIutF5DqnPJo/o7aeKSo/JxFJE5GPROQT53l+55QPF5HlznfeM86CtYHvZX0gX+dsx7uZZlvnArOjfetcEdkOFKlq1E6AEpHpQDXwmKqOc8puBw6o6q1Oss9R1V9GMs5gtfE8NwHVqvqXSMYWChEpAApUdZWIZAArgXOAS4nez6itZ7qAKPycnF1fe6tqtYgkA+8B1wE/A55X1fki8gDwiareH+heVgNp3aHteFW1AfBvnWsiTFWX4lu5ubmZwKPO8aP4/uOOCm08T9RS1VJVXeUcVwEb8e0aGs2fUVvPFJXUp9p5mez8KHAKvq3FIcjPyBJI64LeOjfKKPCaiKwUkcsjHUwXylPVUud4D5AXyWC6yNUissZp4oqa5p7mRKQQmAgsJ0Y+oxbPBFH6OYlIooisBvYCrwOfAxXO1uIQ5HeeJZD4coKqTgK+DVzlNJ/EFGdDsmhvl70fOByYAJQCf41sOB0nIn2A54DrVbWy+XvR+hm18kxR+zmpqldVJ+Db1XUqMDqU+1gCaV1Mbp2rqrud33uBF/D9HycWlDnt1P726r0RjqdTVLXM+Q+8CXiIKPucnHb154AnVfV5pziqP6PWninaPycAVa0A3gKOBbKdrcUhyO88SyCti7mtc0Wkt9MBiIj0Bk4H1gW+Kmo03xr5EuClCMbSaf4vWsd3iaLPyemgnQdsVNW/NXsraj+jtp4pWj8nEckVkWznOB3fYKGN+BLJec5pQX1GNgqrDc6QvDv5cuvcWyIcUqeIyGH4ah3g28r4qWh8JhF5GjgJ39LTZcBvgReBBcBQfMv2X6CqUdEx3cbznISvWUSB7cCPm/Uf9GgicgLwLrAWaHKKb8DXZxCtn1FbzzSbKPycRGQ8vk7yRHyViAWqerPzHTEf6At8DFysqvUB72UJxBhjTCisCcsYY0xILIEYY4wJiSUQY4wxIbEEYowxJiSWQIwxxoTEEogxIRIRb7OVWFd35arNIlLYfIVeY3qipPZPMca0oc5ZDsKYuGQ1EGO6mLPvyu3O3isficgIp7xQRJY4i++9KSJDnfI8EXnB2Z/hExE5zrlVoog85OzZ8JozaxgRudbZm2KNiMyP0GMaYwnEmE5Ib9GEdWGz91yqehTwd3wrGgDcAzyqquOBJ4G7nfK7gXdU9WhgErDeKR8J3KuqY4EK4HtO+a+Aic59rgjXwxnTHpuJbkyIRKRaVfu0Ur4dOEVVtzqL8O1R1X4isg/fxkSNTnmpqvYXkXJgcPNlI5xlw19X1ZHO618Cyar6BxF5Fd8mVC8CLzbb28GYbmU1EGPCQ9s47ojm6xB5+bLP8jvAvfhqKyuaraBqTLeyBGJMeFzY7PeHzvEH+FZ2BrgI3wJ9AG8CP4FDG/1ktXVTEUkAhqjqW8AvgSzga7UgY7qD/cvFmNClO7u6+b2qqv6hvDkisgZfLWK2U3YN8A8R+QVQDlzmlF8HPCgic/HVNH6Cb4Oi1iQCTzhJRoC7nT0djOl21gdiTBdz+kCKVHVfpGMxJpysCcsYY0xIrAZijDEmJFYDMcYYExJLIMYYY0JiCcQYY0xILIEYY4wJiSUQY4wxIfn/Uz61L0/6ADUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Occam factor is: \t0.022478382232582528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Occam factor is: \t0.0019795769180163906\n",
            "time: 386 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}